{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/images/image_1.jpg","path":"images/image_1.jpg","modified":1,"renderable":0},{"_id":"source/images/welcome-image.jpg","path":"images/welcome-image.jpg","modified":1,"renderable":0},{"_id":"source/images/welcome_dark_1.jpg","path":"images/welcome_dark_1.jpg","modified":1,"renderable":0},{"_id":"source/images/welcome_light.jpg","path":"images/welcome_light.jpg","modified":1,"renderable":0},{"_id":"source/images/welcome_light_2.jpg","path":"images/welcome_light_2.jpg","modified":1,"renderable":0},{"_id":"source/images/kafka/kafka-apis.png","path":"images/kafka/kafka-apis.png","modified":1,"renderable":0},{"_id":"source/images/kafka/consumer_groups.png","path":"images/kafka/consumer_groups.png","modified":1,"renderable":0},{"_id":"source/images/kafka/kafka_01.png","path":"images/kafka/kafka_01.png","modified":1,"renderable":0},{"_id":"source/images/kafka/kafka_02.png","path":"images/kafka/kafka_02.png","modified":1,"renderable":0},{"_id":"source/images/kafka/kafka_3_1.png","path":"images/kafka/kafka_3_1.png","modified":1,"renderable":0},{"_id":"source/images/kafka/kafka_3_2.png","path":"images/kafka/kafka_3_2.png","modified":1,"renderable":0},{"_id":"source/images/kafka/log_anatomy.png","path":"images/kafka/log_anatomy.png","modified":1,"renderable":0},{"_id":"source/images/xiamen/welcome_dark_1.jpg","path":"images/xiamen/welcome_dark_1.jpg","modified":1,"renderable":0},{"_id":"themes/zhaoo/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/js/color-mode.js","path":"js/color-mode.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/icons/apple-touch-icon.png","path":"images/icons/apple-touch-icon.png","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/icons/favicon-144x144.png","path":"images/icons/favicon-144x144.png","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/icons/favicon-16x16.png","path":"images/icons/favicon-16x16.png","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/icons/zhaoo-logo.png","path":"images/icons/zhaoo-logo.png","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/icons/favicon-32x32.png","path":"images/icons/favicon-32x32.png","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/cloud.png","path":"images/theme/cloud.png","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/image_1.jpg","path":"images/theme/image_1.jpg","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/loading.gif","path":"images/theme/loading.gif","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/post-image.jpg","path":"images/theme/post-image.jpg","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/welcome-image.jpg","path":"images/theme/welcome-image.jpg","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/welcome_dark_1.jpg","path":"images/theme/welcome_dark_1.jpg","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/welcome_light.jpg","path":"images/theme/welcome_light.jpg","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/images/theme/welcome_light_2.jpg","path":"images/theme/welcome_light_2.jpg","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/daovoice/daovoice.js","path":"lib/daovoice/daovoice.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/gitalk/gitalk.css","path":"lib/gitalk/gitalk.css","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/gitalk/gitalk.js","path":"lib/gitalk/gitalk.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/fancybox/fancybox.css","path":"lib/fancybox/fancybox.css","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/fancybox/fancybox.js","path":"lib/fancybox/fancybox.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/highlight/a11y-dark.css","path":"lib/highlight/a11y-dark.css","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/highlight/highlight.js","path":"lib/highlight/highlight.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/jquery/jquery.js","path":"lib/jquery/jquery.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/lazyload/lazyload.js","path":"lib/lazyload/lazyload.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/pjax/pjax.js","path":"lib/pjax/pjax.js","modified":1,"renderable":1},{"_id":"themes/zhaoo/source/lib/qrcode/qrcode.js","path":"lib/qrcode/qrcode.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/_data/galleries.json","hash":"5433e27f556a154c361aeab1fd8d25ba4d4a181e","modified":1625706263718},{"_id":"source/_data/local_images.json","hash":"7cad1121b29282559694909570e4ec40d710ccf9","modified":1625706263719},{"_id":"source/_posts/Kafka-2.md","hash":"17d80f282c6d25a41210b8cb337062e22aa68581","modified":1625706456126},{"_id":"source/_posts/gugong_600years_diary.md","hash":"759482f20cc7d5e7706ddf0498af19dac988d3bb","modified":1625706263721},{"_id":"source/_posts/hello-world.md","hash":"481bf48fd29271c66b7a0cf607ff10ea1d416eb3","modified":1625706263722},{"_id":"source/_posts/kafka-1.md","hash":"a121f5d8f2be15c396ff031e3761052a00690aa2","modified":1625706263723},{"_id":"source/_posts/kafka-3.md","hash":"fd29784431ab0027e8ce18fb4e01d595e786ff94","modified":1625709924179},{"_id":"source/_posts/xiamen_diary.md","hash":"5cf5ee5de8e1ebb26bd67f23c064ef11a753c692","modified":1625706263724},{"_id":"source/about/index.md","hash":"510a620528a045f4fcf57379f510e43a8e458513","modified":1625706263726},{"_id":"source/categories/index.md","hash":"af4874056e604129c10a75683cf5cd37e2872ee9","modified":1625706263727},{"_id":"source/galleries/index.md","hash":"c1792fd45d489e8f2c24ba5963cb112e2d18f0e8","modified":1625706263728},{"_id":"source/tags/index.md","hash":"ac6092f4765a6475992060e38742909f22799e4a","modified":1625706263887},{"_id":"source/galleries/厦门旅拍/index.md","hash":"20b81c24203e4a8e905977a5e50ba9d4cf0240a6","modified":1625706263730},{"_id":"source/galleries/记事/index.md","hash":"a05ad767d8c9df2909a37f6dc35b71c431304721","modified":1625706263731},{"_id":"source/images/kafka/consumer_groups.png","hash":"619c852e02b223e8af57e857d50759d1921b5d76","modified":1625706263757},{"_id":"source/images/kafka/log_anatomy.png","hash":"7d387eec0de1ebfbcd98a3b0c87aa008b2dbe476","modified":1625706263763},{"_id":"source/images/kafka/kafka-apis.png","hash":"10e6cffc4e472a8f7f6cfdc189d2357fe5f5a779","modified":1625706263758},{"_id":"source/images/kafka/kafka_01.png","hash":"46d799f40b4548e4421cc276e622837c743bc837","modified":1625706263760},{"_id":"source/images/kafka/kafka_3_1.png","hash":"7f9a8822887fc05e0ac211fb5fd621fc5b945f24","modified":1625708741768},{"_id":"source/images/kafka/kafka_3_2.png","hash":"3ecc35d21588f93c3bcc95170ea9705459c15784","modified":1625709642903},{"_id":"source/images/kafka/kafka_02.png","hash":"7b3878c07c1a8701a06fb718f360e5de90b0f199","modified":1625706263762},{"_id":"source/images/welcome-image.jpg","hash":"79e9c9e83a6d8a0bb627e645b770dd2628cd546e","modified":1625706263767},{"_id":"themes/zhaoo/.gitignore","hash":"0d5c2fdbdc974f10150baa12e1fc171a34960ed8","modified":1625706263890},{"_id":"themes/zhaoo/LICENSE","hash":"212211b73f97708e0e243f95eb5adbcdaa1e685d","modified":1625706263891},{"_id":"themes/zhaoo/languages/fr.yml","hash":"b4be1c1592a72012e48df2b3ec41cc9685573e50","modified":1625706263917},{"_id":"themes/zhaoo/README.md","hash":"2a372cad6bc8826e3d8ff280d377aaf8b9a5b381","modified":1625706263896},{"_id":"themes/zhaoo/languages/it.yml","hash":"2b5323867169b25e52009696680a12811b226c1e","modified":1625706263920},{"_id":"themes/zhaoo/_config.yml","hash":"2eedcb83f3b1fc8a5a33319811a6e03c21748258","modified":1625706263898},{"_id":"themes/zhaoo/languages/default.yml","hash":"cb49d6c405ac17b25c8822bc0050fabdf03ae535","modified":1625706263916},{"_id":"themes/zhaoo/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1625706263923},{"_id":"themes/zhaoo/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1625706263924},{"_id":"themes/zhaoo/README_EN.md","hash":"d0186295466e84a78e329773ba5efb9c42cbd0f3","modified":1625706263897},{"_id":"themes/zhaoo/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1625706263922},{"_id":"themes/zhaoo/languages/zh-TW.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1625706263926},{"_id":"themes/zhaoo/languages/zh-CN.yml","hash":"a10d783759847b5c2fc460f3e99000588e76d7ea","modified":1625706263925},{"_id":"themes/zhaoo/layout/categories.ejs","hash":"89f358aa57ce6779c765fce13b42bc5851be8678","modified":1625706263956},{"_id":"themes/zhaoo/layout/galleries.ejs","hash":"b5059a7c664477dd848f98f6c81b80b72aeb724c","modified":1625706263958},{"_id":"themes/zhaoo/layout/index.ejs","hash":"2257045a7b6d593c4171f31152041c6ffd11c7a2","modified":1625706263960},{"_id":"themes/zhaoo/layout/gallery.ejs","hash":"14cadaa9e073fb6980ab0f99a65db421b1236939","modified":1625706263959},{"_id":"themes/zhaoo/layout/layout.ejs","hash":"dfb36f81a780b516b4a97f6287162bfd0e1d5ae4","modified":1625706263960},{"_id":"themes/zhaoo/layout/pure.ejs","hash":"0c1a5ae68fd69bc8d19f5bb0af1afe3656d1cd5d","modified":1625706263962},{"_id":"themes/zhaoo/layout/post.ejs","hash":"92a6e048482fe2b1e86c954ee11b0b2b4c2539f2","modified":1625706263961},{"_id":"themes/zhaoo/layout/tag.ejs","hash":"238c2e2077f01f4fe252ad99db4891a632904cee","modified":1625706263963},{"_id":"themes/zhaoo/layout/category.ejs","hash":"87000e62516e7750ab4f6d878e8231ef78dc4850","modified":1625706263957},{"_id":"themes/zhaoo/layout/archive.ejs","hash":"590b744d722437cfb0b077108a6af58ec18becd2","modified":1625706263955},{"_id":"themes/zhaoo/layout/tags.ejs","hash":"40efc30cbc712282b560491ea537e443a10efa8e","modified":1625706263964},{"_id":"themes/zhaoo/scripts/lazyload.js","hash":"2f6f0e3cfd29e676efe8dc76f062d8cef6569820","modified":1625706263999},{"_id":"themes/zhaoo/scripts/carrier.js","hash":"f0297ca112ffdfed6147e869e4b37ca5d96f0e1b","modified":1625706263997},{"_id":"themes/zhaoo/scripts/caption.js","hash":"ecd6bcdf43bcf2712dbf66956cb0d900bb381a27","modified":1625706263996},{"_id":"themes/zhaoo/scripts/entry.js","hash":"030235848bb787c48bf7078a7c79c9d4fd58722d","modified":1625706263998},{"_id":"themes/zhaoo/scripts/post-image.js","hash":"225f3f153d39f413cad75bb43bd3e2d85cc2d4d2","modified":1625706264001},{"_id":"themes/zhaoo/scripts/merge-config.js","hash":"c87ed49ddd95a900b4e105eafbe8b34cb36ab8d0","modified":1625706264000},{"_id":"themes/zhaoo/scripts/title.js","hash":"d19f444206ea11aff52b5f55756ba082f63b7e6a","modified":1625706264002},{"_id":"themes/zhaoo/layout/_partial/head.ejs","hash":"dd41a812b037cf2078ab49fd02cdf89994cb3014","modified":1625706263939},{"_id":"themes/zhaoo/layout/_partial/script.ejs","hash":"6f29c9b5c9a3de0ac1f8b90b113f69d9992f8d69","modified":1625706263954},{"_id":"themes/zhaoo/source/css/style.styl","hash":"7fa02eac24fa73babaf01ed0a5a17412e9e4ed91","modified":1625706264031},{"_id":"themes/zhaoo/source/js/color-mode.js","hash":"cda2e5d23db3aa3c5dd3f26ce470e7743ba2ed41","modified":1625706264214},{"_id":"themes/zhaoo/_example/source/_data/galleries.json","hash":"b74e764d64c6a0f1fe88e6ff7387e679da3c2efb","modified":1625706263901},{"_id":"themes/zhaoo/source/js/utils.js","hash":"3f698957840955e901613c1717e57d173ed9f6e8","modified":1625706264216},{"_id":"themes/zhaoo/source/js/script.js","hash":"de7547b1899313b105a7f2eaec721e09b0132a22","modified":1625706264215},{"_id":"themes/zhaoo/_example/source/_posts/hexo-theme-zhaoo-doc.md","hash":"e31c483de88963ebc7c4ef5f5e0c9e1c0446aa3b","modified":1625706263903},{"_id":"themes/zhaoo/_example/source/about/index.md","hash":"239dc6fa67a26de7aa9cac61cfc69fe967f94384","modified":1625706263906},{"_id":"themes/zhaoo/_example/source/_data/local_images.json","hash":"7cad1121b29282559694909570e4ec40d710ccf9","modified":1625706263902},{"_id":"themes/zhaoo/_example/source/_posts/hexo-theme-zhaoo.md","hash":"3c3023a7cee4702f56306c995048314e961cbabb","modified":1625706263904},{"_id":"themes/zhaoo/_example/source/tags/index.md","hash":"ac6092f4765a6475992060e38742909f22799e4a","modified":1625706263915},{"_id":"themes/zhaoo/_example/source/galleries/index.md","hash":"e762f0065f939e26517997011351e861c1c892a5","modified":1625706263910},{"_id":"themes/zhaoo/_example/source/categories/index.md","hash":"ac97d61802f6121730ef0df581df44f077b39825","modified":1625706263907},{"_id":"themes/zhaoo/layout/_partial/comments/changyan.ejs","hash":"3452beb86058943cb711719a7651987807787487","modified":1625706263928},{"_id":"themes/zhaoo/layout/_partial/components/fab.ejs","hash":"bfa085d125e9e4c85390c51216a018a303bd0569","modified":1625706263931},{"_id":"themes/zhaoo/layout/_partial/comments/valine.ejs","hash":"5e6287660dfb296cbe63c85713533939e4a2fdde","modified":1625706263930},{"_id":"themes/zhaoo/layout/_partial/components/footer.ejs","hash":"1eaf1655bae68138d21e324a83028b635f24efdf","modified":1625706263932},{"_id":"themes/zhaoo/layout/_partial/comments/gitalk.ejs","hash":"a1845bca3f412dadcad072dfe60eb3911f833559","modified":1625706263929},{"_id":"themes/zhaoo/layout/_partial/components/loading.ejs","hash":"81680b42a796d4d500eda9c5d87d8e80e4b938b2","modified":1625706263934},{"_id":"themes/zhaoo/layout/_partial/components/header.ejs","hash":"79dc1dd669228f017f853acda4a8e51c6a631db4","modified":1625706263933},{"_id":"themes/zhaoo/layout/_partial/components/navbar.ejs","hash":"67c257328ed5ecc2e8131ca67d71b2b300009254","modified":1625706263935},{"_id":"themes/zhaoo/layout/_partial/components/menu.ejs","hash":"8bfbdc6c78970b7c6fd946b9932cb0e961178169","modified":1625706263935},{"_id":"themes/zhaoo/layout/_partial/components/paginator.ejs","hash":"b9810cd5ad253a4ce2050f571fc0bb8e8b0f2580","modified":1625706263936},{"_id":"themes/zhaoo/layout/_partial/components/scrollbar.ejs","hash":"5abc155f13e03bd1203d485a24658d73a27b246a","modified":1625706263937},{"_id":"themes/zhaoo/layout/_partial/index/item.ejs","hash":"3dccb148f5205719643bddebb7dbb5d11a45a187","modified":1625706263940},{"_id":"themes/zhaoo/layout/_partial/components/search.ejs","hash":"bc270f445892aaea460b057107d8ba2fc89635ae","modified":1625706263938},{"_id":"themes/zhaoo/layout/_partial/index/post.ejs","hash":"83a715a96a0091aaf15919b7bc4df67b96827144","modified":1625706263941},{"_id":"themes/zhaoo/layout/_partial/plugins/analytics.ejs","hash":"a512bca486f0a1b4dbcc19d50cb02f6e211055df","modified":1625706263943},{"_id":"themes/zhaoo/layout/_partial/index/preview.ejs","hash":"a271191f768401206ca8a71b13d8e06e6f773538","modified":1625706263942},{"_id":"themes/zhaoo/layout/_partial/plugins/seo.ejs","hash":"f9522a8b323b97b3c224dbfab590a5fd1812dbcb","modified":1625706263945},{"_id":"themes/zhaoo/layout/_partial/plugins/daovoice.ejs","hash":"5f549e08701281dcbc215d8fcd727474c81e906b","modified":1625706263944},{"_id":"themes/zhaoo/layout/_partial/post/article.ejs","hash":"d886a30975916d8f1555674f1b2441ed25579bbb","modified":1625706263948},{"_id":"themes/zhaoo/layout/_partial/post/comments.ejs","hash":"23ee3e0e52d4813d07a3fa1cf23b05195823a7cc","modified":1625706263948},{"_id":"themes/zhaoo/layout/_partial/post/copyright.ejs","hash":"4d2a20ef75c244a34456b40d47bdcdf9cc8abdc9","modified":1625706263949},{"_id":"themes/zhaoo/layout/_partial/plugins/visitors.ejs","hash":"df441c30f5d4168fadc5d70f71da5695295d86ca","modified":1625706263946},{"_id":"themes/zhaoo/layout/_partial/post/head.ejs","hash":"60ef5cf812d7735a1c46263fb963b7fc23c80d2b","modified":1625706263951},{"_id":"themes/zhaoo/layout/_partial/post/nav.ejs","hash":"be8910cac98be268aa96f9f7f6c44aa2145d706f","modified":1625706263952},{"_id":"themes/zhaoo/layout/_partial/post/tag.ejs","hash":"9a5276ffdccf9c808adeb31407cc7da0de5e62df","modified":1625706263953},{"_id":"themes/zhaoo/layout/_partial/post/toc.ejs","hash":"ab99befc8c22ea8c25dbaae606f0bd59f447637e","modified":1625706263953},{"_id":"themes/zhaoo/layout/_partial/post/donate.ejs","hash":"5c3bc6f4aa594bae63a9c7a21b5e812292c6e63a","modified":1625706263950},{"_id":"themes/zhaoo/source/css/_base/color-mode.styl","hash":"2b1682c1ed7c5e89a321555512d5b085455fc682","modified":1625706264004},{"_id":"themes/zhaoo/source/css/_base/reset.styl","hash":"43e356911edcf4097a9023c349fb777a161601b3","modified":1625706264005},{"_id":"themes/zhaoo/source/css/_base/zui.styl","hash":"407360c471a60b0732004e6bd4b34a21ec83ede0","modified":1625706264006},{"_id":"themes/zhaoo/source/css/_components/fab.styl","hash":"2f4fec084a9b9ad4e6ce5686a28d626d5197696e","modified":1625706264009},{"_id":"themes/zhaoo/source/css/_components/common.styl","hash":"a4e466d3dbf4863b4f243b5e67ae221971bfa989","modified":1625706264008},{"_id":"themes/zhaoo/source/css/_components/footer.styl","hash":"ebd937d9bcc9942b3f59fcc330117be9909c3ae3","modified":1625706264009},{"_id":"themes/zhaoo/source/css/_components/menu.styl","hash":"739b064df0921d113f269544b6144a425094c3ed","modified":1625706264011},{"_id":"themes/zhaoo/source/css/_components/navbar.styl","hash":"1b34e70cb0f958d08c7d31dbd5830ae89fb2d0bc","modified":1625706264012},{"_id":"themes/zhaoo/source/css/_components/header.styl","hash":"c4f486ff965a21546b0e1497aad1ed1c75d5b089","modified":1625706264010},{"_id":"themes/zhaoo/source/css/_components/paginator.styl","hash":"579c1a6aec3c46b2733b1687161ffbdbaaec6b54","modified":1625706264013},{"_id":"themes/zhaoo/source/css/_components/preview.styl","hash":"3781fb0d8c9bbbee132dad555bacf804e9702960","modified":1625706264014},{"_id":"themes/zhaoo/source/css/_components/scrollbar.styl","hash":"98df51db0c99897a4c58bbdcf8954c4cf148a607","modified":1625706264015},{"_id":"themes/zhaoo/source/css/_components/search.styl","hash":"ac65010dda7d79e002f6702602a7de4b873aec4e","modified":1625706264016},{"_id":"themes/zhaoo/source/css/_pages/pages.styl","hash":"f561158053bd9f84e07737494626f141ae3a28b2","modified":1625706264029},{"_id":"themes/zhaoo/source/css/_variables/variables.styl","hash":"bca8f684195f1c052b9b5546b4b6ec558f54d4bf","modified":1625706264031},{"_id":"themes/zhaoo/source/images/icons/apple-touch-icon.png","hash":"c1d16404a57db24e985204e7b2b97fa45d5fea0b","modified":1625706264033},{"_id":"themes/zhaoo/source/images/icons/favicon-16x16.png","hash":"86cc7a07ccf09deff3de7b0ef2f82daa282a8b8e","modified":1625706264035},{"_id":"themes/zhaoo/source/images/icons/zhaoo-logo.png","hash":"50f9f5de4207847bba6aecc4c21d21d79f0001fb","modified":1625706264037},{"_id":"themes/zhaoo/source/images/icons/favicon-32x32.png","hash":"7b095984bd7d07e10fa9b0df8347a933eba8537c","modified":1625706264036},{"_id":"themes/zhaoo/source/images/icons/favicon-144x144.png","hash":"e54f440ff564f1235f9c399e2cd435dd502ceb84","modified":1625706264034},{"_id":"themes/zhaoo/source/images/theme/loading.gif","hash":"db91090dd60098086993953f88c37a332eea70d7","modified":1625706264075},{"_id":"themes/zhaoo/source/lib/gitalk/gitalk.css","hash":"2300f2218690a06dce07fe7eeb31bcbf014907f7","modified":1625706264227},{"_id":"themes/zhaoo/source/lib/fancybox/fancybox.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1625706264224},{"_id":"themes/zhaoo/source/lib/highlight/a11y-dark.css","hash":"9f0c935216015dd88251a6c366bdd00abfe65982","modified":1625706264231},{"_id":"themes/zhaoo/source/lib/highlight/highlight.js","hash":"976504107e1449a98ede49e0b06480a6818ae39e","modified":1625706264232},{"_id":"themes/zhaoo/source/lib/lazyload/lazyload.js","hash":"322b05c0beb539459214aab2d4cec386ccc2c294","modified":1625706264236},{"_id":"themes/zhaoo/source/lib/qrcode/qrcode.js","hash":"749139770957126aa0cd39a89e974f11d1dbba5d","modified":1625706264239},{"_id":"themes/zhaoo/source/lib/pjax/pjax.js","hash":"a1e9fe6ad32e947451584531db3fcb0924354a96","modified":1625706264237},{"_id":"themes/zhaoo/_example/source/galleries/colorful/index.md","hash":"1d62f01d2b06bdd51cbac17bb69b031a7205317b","modified":1625706263909},{"_id":"themes/zhaoo/_example/source/galleries/记事/index.md","hash":"a05ad767d8c9df2909a37f6dc35b71c431304721","modified":1625706263913},{"_id":"themes/zhaoo/_example/source/galleries/深圳日记/index.md","hash":"0cac4cff71e988970dce718b5c78e023f066dd52","modified":1625706263911},{"_id":"themes/zhaoo/source/css/_pages/_archive/archive.styl","hash":"6f50017eb617c2b9eb400eef810405032955d496","modified":1625706264017},{"_id":"themes/zhaoo/source/css/_pages/_category/categories.styl","hash":"ce06edbffa932fe31b39f0aec6b07524fd084159","modified":1625706264019},{"_id":"themes/zhaoo/source/css/_pages/_gallery/galleries.styl","hash":"d1ccfe444eec69056ec0cd9431c5c04002283a1f","modified":1625706264022},{"_id":"themes/zhaoo/source/css/_pages/_gallery/gallery.styl","hash":"78da3b485274d665f569d8412932446ce2867a28","modified":1625706264023},{"_id":"themes/zhaoo/source/css/_pages/_index/index.styl","hash":"23c1826768061f2380cc9890321855b87bc1ca60","modified":1625706264025},{"_id":"themes/zhaoo/source/css/_pages/_post/article.styl","hash":"82c8048b7d994ca710a64583332757c4c79efc1b","modified":1625706264026},{"_id":"themes/zhaoo/source/css/_pages/_tag/tags.styl","hash":"09232e1a81af46cba6401cf0817e1d64c2f7cb8e","modified":1625706264028},{"_id":"themes/zhaoo/source/css/_pages/_post/toc.styl","hash":"c57a90d296185225ff21df30f0a4a361072a840b","modified":1625706264027},{"_id":"themes/zhaoo/source/lib/fancybox/fancybox.js","hash":"eef46b6fb2e460838cd7328a6e13ecda0cb1e194","modified":1625706264226},{"_id":"themes/zhaoo/source/lib/jquery/jquery.js","hash":"b15f7cfa79519756dff1ad22553fd0ed09024343","modified":1625706264234},{"_id":"themes/zhaoo/source/images/theme/cloud.png","hash":"fdf44a91026ad999dca2f0a42213aabebd783c98","modified":1625706264040},{"_id":"themes/zhaoo/source/images/theme/post-image.jpg","hash":"7fb1947508a411177829cedac8d5922671cac2b0","modified":1625706264084},{"_id":"themes/zhaoo/source/lib/gitalk/gitalk.js","hash":"668a325f964a57aace92f46de8ee709768ccd251","modified":1625706264229},{"_id":"themes/zhaoo/screenshots/menu.png","hash":"0f4220734a52953636a5273d64a03c8b01ec6098","modified":1625706263987},{"_id":"themes/zhaoo/source/images/theme/welcome-image.jpg","hash":"79e9c9e83a6d8a0bb627e645b770dd2628cd546e","modified":1625706264090},{"_id":"themes/zhaoo/screenshots/galleries.png","hash":"8ba5a26c7932d5ef456cc799bbc00c5f468e54cc","modified":1625706263976},{"_id":"themes/zhaoo/source/lib/daovoice/daovoice.js","hash":"0a666f89f583159c89d3ba512e5cacbe0633f28f","modified":1625706264222},{"_id":"themes/zhaoo/screenshots/article.png","hash":"74706d28c479a20f77c1bd4454879cabf8784ca6","modified":1625706263971},{"_id":"themes/zhaoo/screenshots/index.png","hash":"a95df16106c813b92f14071bac3d38bc53a1bc00","modified":1625706263984},{"_id":"themes/zhaoo/screenshots/preview.png","hash":"2b4271a275b9ff8318d00ab04504a109ec931fe7","modified":1625706263994},{"_id":"source/images/welcome_light_2.jpg","hash":"b9e4f79b5c027af4e0bfc3388ab6121a577f7b11","modified":1625706263868},{"_id":"themes/zhaoo/source/images/theme/welcome_light_2.jpg","hash":"b9e4f79b5c027af4e0bfc3388ab6121a577f7b11","modified":1625706264212},{"_id":"source/images/welcome_dark_1.jpg","hash":"65303adb45f666ec9ed84279e23decaf7d54fffa","modified":1625706263783},{"_id":"source/images/xiamen/welcome_dark_1.jpg","hash":"65303adb45f666ec9ed84279e23decaf7d54fffa","modified":1625706263885},{"_id":"themes/zhaoo/source/images/theme/welcome_dark_1.jpg","hash":"65303adb45f666ec9ed84279e23decaf7d54fffa","modified":1625706264108},{"_id":"source/images/image_1.jpg","hash":"8bd0c620db0fe61aaa6e63ce4bf296ef0afdbd51","modified":1625706263754},{"_id":"themes/zhaoo/source/images/theme/image_1.jpg","hash":"8bd0c620db0fe61aaa6e63ce4bf296ef0afdbd51","modified":1625706264070},{"_id":"source/images/welcome_light.jpg","hash":"1300716567353c76b7efd6a2b6099b5184ecc968","modified":1625706263848},{"_id":"themes/zhaoo/source/images/theme/welcome_light.jpg","hash":"1300716567353c76b7efd6a2b6099b5184ecc968","modified":1625706264190},{"_id":"public/about/index.html","hash":"3161c5c4503b75f02f1b5a06a16db1a337b8ff95","modified":1625710080323},{"_id":"public/categories/index.html","hash":"27e9a7c15d7770925edf01b14ad0a46dd0ca2258","modified":1625710080323},{"_id":"public/galleries/index.html","hash":"26b3b52963a0182ec1ef98b375492adf2f5d30ac","modified":1625710080323},{"_id":"public/tags/index.html","hash":"33fe02174c288dd1625f9ec595a3cec01d524db6","modified":1625710080323},{"_id":"public/galleries/厦门旅拍/index.html","hash":"8823b57c721afa0b390bf701bfd3730ed15d7097","modified":1625710080323},{"_id":"public/galleries/记事/index.html","hash":"b39317b692cee5b1b0572cdb7737f02be336b5db","modified":1625710080323},{"_id":"public/2021/07/08/hello-world/index.html","hash":"2531891c9d7202804d3b06fbf1f39fd7d1c986b9","modified":1625710080323},{"_id":"public/2021/07/07/gugong_600years_diary/index.html","hash":"e4f6be426d1327ad487c239f3f4c9cd833d52e40","modified":1625710080323},{"_id":"public/2021/07/04/Kafka-2/index.html","hash":"ad1037c7c8bb99e29bcddc64b9456221bc3b613f","modified":1625710080323},{"_id":"public/2021/07/01/xiamen_diary/index.html","hash":"ec319f65de4638286e52b63882f43ff25f6f3614","modified":1625710080323},{"_id":"public/categories/技术/index.html","hash":"a11fb4a695c7a9057cd2d473e9336f10addc32a7","modified":1625710080323},{"_id":"public/categories/日记/index.html","hash":"9a6961d7e2e0cf6b93009d25ce7e55f07fcdd9ab","modified":1625710080323},{"_id":"public/archives/index.html","hash":"914069b4cb79aaf4a6890a3a157f9d20fb267c34","modified":1625710080323},{"_id":"public/archives/2021/index.html","hash":"7fce8b2a8c5b6c7e9db27af6a70d692161bdb6d2","modified":1625710080323},{"_id":"public/archives/2021/07/index.html","hash":"66053564f19d9d7fe78a59ef5dfc1d5490c6a8a2","modified":1625710080323},{"_id":"public/index.html","hash":"77a9a9dbf890ff17b56ab017c8ba01cddaceefdc","modified":1625710080323},{"_id":"public/2021/07/06/kafka-3/index.html","hash":"d3c31af386d9dae2b9ac6d193a898530095f5b43","modified":1625710080323},{"_id":"public/2021/07/01/kafka-1/index.html","hash":"9c3a0b0adc4fc14748a26dcacc7577c960fe46d8","modified":1625710080323},{"_id":"public/tags/Kafka/index.html","hash":"fa35152b2b39aedff68cdb9cc9c59bb1fb73574f","modified":1625710080323},{"_id":"public/images/kafka/consumer_groups.png","hash":"619c852e02b223e8af57e857d50759d1921b5d76","modified":1625710080323},{"_id":"public/images/kafka/log_anatomy.png","hash":"7d387eec0de1ebfbcd98a3b0c87aa008b2dbe476","modified":1625710080323},{"_id":"public/images/icons/favicon-144x144.png","hash":"e54f440ff564f1235f9c399e2cd435dd502ceb84","modified":1625710080323},{"_id":"public/images/icons/favicon-16x16.png","hash":"86cc7a07ccf09deff3de7b0ef2f82daa282a8b8e","modified":1625710080323},{"_id":"public/images/icons/apple-touch-icon.png","hash":"c1d16404a57db24e985204e7b2b97fa45d5fea0b","modified":1625710080323},{"_id":"public/images/icons/zhaoo-logo.png","hash":"50f9f5de4207847bba6aecc4c21d21d79f0001fb","modified":1625710080323},{"_id":"public/images/icons/favicon-32x32.png","hash":"7b095984bd7d07e10fa9b0df8347a933eba8537c","modified":1625710080323},{"_id":"public/images/theme/loading.gif","hash":"db91090dd60098086993953f88c37a332eea70d7","modified":1625710080323},{"_id":"public/images/kafka/kafka-apis.png","hash":"10e6cffc4e472a8f7f6cfdc189d2357fe5f5a779","modified":1625710080323},{"_id":"public/images/kafka/kafka_01.png","hash":"46d799f40b4548e4421cc276e622837c743bc837","modified":1625710080323},{"_id":"public/images/kafka/kafka_3_1.png","hash":"7f9a8822887fc05e0ac211fb5fd621fc5b945f24","modified":1625710080323},{"_id":"public/images/kafka/kafka_3_2.png","hash":"3ecc35d21588f93c3bcc95170ea9705459c15784","modified":1625710080323},{"_id":"public/images/kafka/kafka_02.png","hash":"7b3878c07c1a8701a06fb718f360e5de90b0f199","modified":1625710080323},{"_id":"public/images/theme/cloud.png","hash":"fdf44a91026ad999dca2f0a42213aabebd783c98","modified":1625710080323},{"_id":"public/images/theme/post-image.jpg","hash":"7fb1947508a411177829cedac8d5922671cac2b0","modified":1625710080323},{"_id":"public/js/color-mode.js","hash":"33cd307624e32035ea4544c9a6a4676ef9f70beb","modified":1625710080323},{"_id":"public/js/utils.js","hash":"359461693c5a1c8f9fb159c2dfb78051d0b351e1","modified":1625710080323},{"_id":"public/lib/fancybox/fancybox.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1625710080323},{"_id":"public/lib/highlight/a11y-dark.css","hash":"9f0c935216015dd88251a6c366bdd00abfe65982","modified":1625710080323},{"_id":"public/lib/lazyload/lazyload.js","hash":"338318e930487b2791a7bcf53ad4601630cc41e2","modified":1625710080323},{"_id":"public/lib/pjax/pjax.js","hash":"0ced78e5c97127948f5bfbfbb80c4fce5c0f671e","modified":1625710080323},{"_id":"public/lib/qrcode/qrcode.js","hash":"f424bd339870510d1160d1c5da5d698aedbb452e","modified":1625710080323},{"_id":"public/css/style.css","hash":"2feb8289235126f6ed7bf44514d6d6d8c9292c91","modified":1625710080323},{"_id":"public/js/script.js","hash":"6d73d31593faf80f5b778cf994f2dfea37820166","modified":1625710080323},{"_id":"public/lib/gitalk/gitalk.css","hash":"99f6725b386bdb0f52d15b0dd7877eaf1ad4c918","modified":1625710080323},{"_id":"public/images/welcome-image.jpg","hash":"79e9c9e83a6d8a0bb627e645b770dd2628cd546e","modified":1625710080323},{"_id":"public/images/theme/welcome-image.jpg","hash":"79e9c9e83a6d8a0bb627e645b770dd2628cd546e","modified":1625710080323},{"_id":"public/lib/highlight/highlight.js","hash":"a52ef27b8a21963326b05ef06f6ee104b8b94e7e","modified":1625710080323},{"_id":"public/lib/fancybox/fancybox.js","hash":"6181412e73966696d08e1e5b1243a572d0f22ba6","modified":1625710080323},{"_id":"public/lib/jquery/jquery.js","hash":"88523924351bac0b5d560fe0c5781e2556e7693d","modified":1625710080323},{"_id":"public/lib/gitalk/gitalk.js","hash":"266500948447c95aeea95ef6760f192afc96fd5e","modified":1625710080323},{"_id":"public/images/welcome_light_2.jpg","hash":"b9e4f79b5c027af4e0bfc3388ab6121a577f7b11","modified":1625710080323},{"_id":"public/images/theme/welcome_light_2.jpg","hash":"b9e4f79b5c027af4e0bfc3388ab6121a577f7b11","modified":1625710080323},{"_id":"public/lib/daovoice/daovoice.js","hash":"180375e6fc5a5a71810b5e83109c0ce1533bbc5a","modified":1625710080323},{"_id":"public/images/welcome_dark_1.jpg","hash":"65303adb45f666ec9ed84279e23decaf7d54fffa","modified":1625710080323},{"_id":"public/images/xiamen/welcome_dark_1.jpg","hash":"65303adb45f666ec9ed84279e23decaf7d54fffa","modified":1625710080323},{"_id":"public/images/theme/welcome_dark_1.jpg","hash":"65303adb45f666ec9ed84279e23decaf7d54fffa","modified":1625710080323},{"_id":"public/images/image_1.jpg","hash":"8bd0c620db0fe61aaa6e63ce4bf296ef0afdbd51","modified":1625710080323},{"_id":"public/images/theme/image_1.jpg","hash":"8bd0c620db0fe61aaa6e63ce4bf296ef0afdbd51","modified":1625710080323},{"_id":"public/images/welcome_light.jpg","hash":"1300716567353c76b7efd6a2b6099b5184ecc968","modified":1625710080323},{"_id":"public/images/theme/welcome_light.jpg","hash":"1300716567353c76b7efd6a2b6099b5184ecc968","modified":1625710080323}],"Category":[{"name":"技术","_id":"ckqu9t2qe0008y8vaes7z0tz9"},{"name":"日记","_id":"ckqu9t2qj000ey8vaao7v0c1h"}],"Data":[{"_id":"galleries","data":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}]},{"_id":"local_images","data":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}],"Page":[{"title":"It's me","date":"2021-07-02T04:45:42.000Z","image":"/images/theme/image_1.jpg","copyright":false,"_content":"","source":"about/index.md","raw":"---\ntitle: It's me\ndate: 2021-07-02 12:45:42\nimage: /images/theme/image_1.jpg\ncopyright: false\n---\n","updated":"2021-07-08T01:04:23.726Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckqu9t2q00000y8va9gzw47ve","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""},{"title":"categories","date":"2021-07-02T04:38:44.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2021-07-02 12:38:44\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2021-07-08T01:04:23.727Z","path":"categories/index.html","comments":1,"_id":"ckqu9t2q30001y8vae8eqcm5c","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""},{"title":"galleries","date":"2021-06-29T04:39:40.000Z","layout":"galleries","_content":"","source":"galleries/index.md","raw":"---\ntitle: galleries\ndate: 2021-06-29 12:39:40\nlayout: \"galleries\"\n---\n","updated":"2021-07-08T01:04:23.728Z","path":"galleries/index.html","comments":1,"_id":"ckqu9t2q40002y8va7sr775a7","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""},{"title":"标签","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ntype: \"tags\"\nlayout: \"tags\"\n---\n","date":"2021-07-08T01:04:23.887Z","updated":"2021-07-08T01:04:23.887Z","path":"tags/index.html","comments":1,"_id":"ckqu9t2q50003y8va92ck6771","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""},{"title":"厦门旅拍","layout":"gallery","_content":"","source":"galleries/厦门旅拍/index.md","raw":"---\ntitle: 厦门旅拍\nlayout: \"gallery\"\n---","date":"2021-07-08T01:04:23.730Z","updated":"2021-07-08T01:04:23.730Z","path":"galleries/厦门旅拍/index.html","comments":1,"_id":"ckqu9t2q60004y8vae472ce9e","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""},{"title":"记事","layout":"gallery","_content":"","source":"galleries/记事/index.md","raw":"---\ntitle: 记事\nlayout: \"gallery\"\n---","date":"2021-07-08T01:04:23.731Z","updated":"2021-07-08T01:04:23.731Z","path":"galleries/记事/index.html","comments":1,"_id":"ckqu9t2q60005y8vaauh30anw","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""}],"Post":[{"title":"Kafka(二)","date":"2021-07-04T12:58:15.000Z","keywords":"Kafka,kafka","_content":"# **Apache Kafka 是一个分布式流处理平台。**\n\n## 1.0 Kafka结构\n\nKafka集群包含若干Producer，若干broker（broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将信息发布到broker，Consumer使用pull模式从broker订阅并消费消息。\n\n![](/images/kafka/kafka_02.png)\n\n## 2.0 Producer消息\n\nProducer发送消息到broker时，会根据Partition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就视线里负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O就会变成这个Topic的性能瓶颈，但有了Partition后，不同的消息可以并行写入不同broker的不同的Partition里，可以极大地提高吞吐率。\n\n## 3.0 Topics和Partition\n\nTopic在逻辑上可以被认为是一个queue，每条消费都必须指定他的Topic，可以简单理解为必须指名把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。（顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。\n\n## 4.0 Consumer Group\n\n![](/images/kafka/consumer_groups.png)\n\n使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group 可同时消费这一消息。\n\n这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Comsumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不是需要多次发送消息到不同的Topic.\n\n\n## 5.0 push and pull\n\nKafka作为一个消息系统遵循了传统的方式，选择又Producer向broker push消息并由Consumer从broker pull消息。\n\npush模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。\n\nKafka更适合pull模式，pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。","source":"_posts/Kafka-2.md","raw":"---\ntitle: Kafka(二)\ndate: 2021-07-04 20:58:15\ntags: Kafka\ncategories: 技术\nkeywords: Kafka,kafka\n---\n# **Apache Kafka 是一个分布式流处理平台。**\n\n## 1.0 Kafka结构\n\nKafka集群包含若干Producer，若干broker（broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将信息发布到broker，Consumer使用pull模式从broker订阅并消费消息。\n\n![](/images/kafka/kafka_02.png)\n\n## 2.0 Producer消息\n\nProducer发送消息到broker时，会根据Partition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就视线里负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O就会变成这个Topic的性能瓶颈，但有了Partition后，不同的消息可以并行写入不同broker的不同的Partition里，可以极大地提高吞吐率。\n\n## 3.0 Topics和Partition\n\nTopic在逻辑上可以被认为是一个queue，每条消费都必须指定他的Topic，可以简单理解为必须指名把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。（顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。\n\n## 4.0 Consumer Group\n\n![](/images/kafka/consumer_groups.png)\n\n使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group 可同时消费这一消息。\n\n这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Comsumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不是需要多次发送消息到不同的Topic.\n\n\n## 5.0 push and pull\n\nKafka作为一个消息系统遵循了传统的方式，选择又Producer向broker push消息并由Consumer从broker pull消息。\n\npush模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。\n\nKafka更适合pull模式，pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。","slug":"Kafka-2","published":1,"updated":"2021-07-08T01:07:36.126Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckqu9t2q90006y8vahrtyb0ku","content":"<h1 id=\"Apache-Kafka-是一个分布式流处理平台。\"><a href=\"#Apache-Kafka-是一个分布式流处理平台。\" class=\"headerlink\" title=\"Apache Kafka 是一个分布式流处理平台。\"></a><strong>Apache Kafka 是一个分布式流处理平台。</strong></h1><h2 id=\"1-0-Kafka结构\"><a href=\"#1-0-Kafka结构\" class=\"headerlink\" title=\"1.0 Kafka结构\"></a>1.0 Kafka结构</h2><p>Kafka集群包含若干Producer，若干broker（broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将信息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>\n<p><img src=\"/images/kafka/kafka_02.png\"></p>\n<h2 id=\"2-0-Producer消息\"><a href=\"#2-0-Producer消息\" class=\"headerlink\" title=\"2.0 Producer消息\"></a>2.0 Producer消息</h2><p>Producer发送消息到broker时，会根据Partition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就视线里负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O就会变成这个Topic的性能瓶颈，但有了Partition后，不同的消息可以并行写入不同broker的不同的Partition里，可以极大地提高吞吐率。</p>\n<h2 id=\"3-0-Topics和Partition\"><a href=\"#3-0-Topics和Partition\" class=\"headerlink\" title=\"3.0 Topics和Partition\"></a>3.0 Topics和Partition</h2><p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定他的Topic，可以简单理解为必须指名把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。（顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>\n<h2 id=\"4-0-Consumer-Group\"><a href=\"#4-0-Consumer-Group\" class=\"headerlink\" title=\"4.0 Consumer Group\"></a>4.0 Consumer Group</h2><p><img src=\"/images/kafka/consumer_groups.png\"></p>\n<p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group 可同时消费这一消息。</p>\n<p>这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Comsumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不是需要多次发送消息到不同的Topic.</p>\n<h2 id=\"5-0-push-and-pull\"><a href=\"#5-0-push-and-pull\" class=\"headerlink\" title=\"5.0 push and pull\"></a>5.0 push and pull</h2><p>Kafka作为一个消息系统遵循了传统的方式，选择又Producer向broker push消息并由Consumer从broker pull消息。</p>\n<p>push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。</p>\n<p>Kafka更适合pull模式，pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p>\n","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":"<h1 id=\"Apache-Kafka-是一个分布式流处理平台。\"><a href=\"#Apache-Kafka-是一个分布式流处理平台。\" class=\"headerlink\" title=\"Apache Kafka 是一个分布式流处理平台。\"></a><strong>Apache Kafka 是一个分布式流处理平台。</strong></h1><h2 id=\"1-0-Kafka结构\"><a href=\"#1-0-Kafka结构\" class=\"headerlink\" title=\"1.0 Kafka结构\"></a>1.0 Kafka结构</h2><p>Kafka集群包含若干Producer，若干broker（broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将信息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>\n<p><img src=\"/images/kafka/kafka_02.png\"></p>\n<h2 id=\"2-0-Producer消息\"><a href=\"#2-0-Producer消息\" class=\"headerlink\" title=\"2.0 Producer消息\"></a>2.0 Producer消息</h2><p>Producer发送消息到broker时，会根据Partition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就视线里负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O就会变成这个Topic的性能瓶颈，但有了Partition后，不同的消息可以并行写入不同broker的不同的Partition里，可以极大地提高吞吐率。</p>\n<h2 id=\"3-0-Topics和Partition\"><a href=\"#3-0-Topics和Partition\" class=\"headerlink\" title=\"3.0 Topics和Partition\"></a>3.0 Topics和Partition</h2><p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定他的Topic，可以简单理解为必须指名把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。创建一个topic时，同时可以指定分区数目，分区数越多，其吞吐量也越大，但是需要的资源也越多，同时会导致更高的不可用性，kafka在接收到生产者发送的消息之后，会根据均衡策略将消息存储到不同的分区中。（顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>\n<h2 id=\"4-0-Consumer-Group\"><a href=\"#4-0-Consumer-Group\" class=\"headerlink\" title=\"4.0 Consumer Group\"></a>4.0 Consumer Group</h2><p><img src=\"/images/kafka/consumer_groups.png\"></p>\n<p>使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group 可同时消费这一消息。</p>\n<p>这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Comsumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不是需要多次发送消息到不同的Topic.</p>\n<h2 id=\"5-0-push-and-pull\"><a href=\"#5-0-push-and-pull\" class=\"headerlink\" title=\"5.0 push and pull\"></a>5.0 push and pull</h2><p>Kafka作为一个消息系统遵循了传统的方式，选择又Producer向broker push消息并由Consumer从broker pull消息。</p>\n<p>push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。</p>\n<p>Kafka更适合pull模式，pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p>\n"},{"layout":"galleries","title":"test","date":"2021-07-07T02:13:11.000Z","_content":"","source":"_posts/gugong_600years_diary.md","raw":"---\nlayout: galleries\ntitle: test\ndate: 2021-07-07 10:13:11\ntags:\n---\n","slug":"gugong_600years_diary","published":1,"updated":"2021-07-08T01:04:23.721Z","comments":1,"photos":[],"link":"","_id":"ckqu9t2qc0007y8vadetccl3f","content":"","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":""},{"title":"Hello World","copyright":false,"_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ncopyright: false\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2021-07-08T01:04:23.721Z","updated":"2021-07-08T01:04:23.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckqu9t2qg000ay8va4cgz67qh","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"kafka(三)","date":"2021-07-06T12:10:21.000Z","keywords":"Kafka,kafka","top":48,"_content":"# **Apache Kafka 是一个分布式流处理平台。**\n\n## 1.0 Kafka HA 设计\n\n### 1.1 将Replica均匀分布到整个集群\n\nKafka尽力把所有的Partition均匀分配到集群上是为了负载均衡。 一个典型的部署方式是一个Topic的Partition数量大于broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。\n\n### 1.2 Data Replication(副本策略)\n\nKafka的高可靠性的保障来源于其健壮的副本（replication）策略。\n\n#### 1.2.1 消息传递同步策略\n\nproducer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少，Producer只将该消息发送到该Partition的Leader。Leader会将消息写入本地log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。\n\nKafka Replication的数据流如下图所示：\n\n![](/images/kafka/kafka_3_1.png)\n\n#### 1.2.2 选举Leader\n\n最简单最直观的方案是，所有Follower都在ZooKeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（ZooKeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。\n\n但是该方法会有3个问题：\n\n1.split-brain 这是由ZooKeeper的特性引起的，虽然ZooKeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致\n\n2.herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整\n\n3.ZooKeeper负载过重 每个Replica都要为此在ZooKeeper上注册一个Watch，当集群规模增加到几千个Partition时ZooKeeper负载会过重。\n\nKafka 0.8.*的Leader Election方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比ZooKeeper Queue的方式更高效）通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。\n\n## 2.0 Kafka 高可用\n\n### 2.1 Replication\n\n在Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与Kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。\n\n如果Producer使用同步模式则Producer会在尝试重新发送message.send.max.retries（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成数据的阻塞，后者会造成本应发往该Broker的数据的丢失。\n\n如果Producer使用异步模式，则Producer会尝试重新发送message.send.max.retries（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。同时，Kafka的Producer并未对异步模式提供callback接口。\n\n由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。\n\n### 2.1.2 Leader Election\n\n引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。\n\n因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。\n\n## 3.0 HA 相关ZooKeeper结构\n\n![](/images/kafka/kafka_3_2.png)\n\n### 3.1 admin\n\n该目录下znode只有在有相关操作时才会存在，操作结束时会将其删除\n\n/admin/reassign_partitions用于将一些Partition分配到不同的broker集合上。对于每个待重新分配的Partition，Kafka会在该znode上存储其所有的Replica和相应的Broker id。该znode由管理进程创建并且一旦重新分配成功它将会被自动移除。\n\n### 3.2 broker\n\n即/brokers/ids/[brokerId]）存储“活着”的broker信息。\n\ntopic注册信息（/brokers/topics/[topic]），存储该topic的所有partition的所有replica所在的broker id，第一个replica即为preferred replica，对一个给定的partition，它在同一个broker上最多只有一个replica,因此broker id可作为replica id。\n\n### 3.3 controller\n\n/controller -> int (broker id of the controller)存储当前controller的信息\n\n/controller_epoch -> int (epoch)直接以整数形式存储controller epoch，而非像其它znode一样以JSON字符串形式存储。\n\n","source":"_posts/kafka-3.md","raw":"---\ntitle: kafka(三)\ndate: 2021-07-06 20:10:21\ntags: Kafka\ncategories: 技术\nkeywords: Kafka,kafka\ntop: 48\n---\n# **Apache Kafka 是一个分布式流处理平台。**\n\n## 1.0 Kafka HA 设计\n\n### 1.1 将Replica均匀分布到整个集群\n\nKafka尽力把所有的Partition均匀分配到集群上是为了负载均衡。 一个典型的部署方式是一个Topic的Partition数量大于broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。\n\n### 1.2 Data Replication(副本策略)\n\nKafka的高可靠性的保障来源于其健壮的副本（replication）策略。\n\n#### 1.2.1 消息传递同步策略\n\nproducer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少，Producer只将该消息发送到该Partition的Leader。Leader会将消息写入本地log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。\n\nKafka Replication的数据流如下图所示：\n\n![](/images/kafka/kafka_3_1.png)\n\n#### 1.2.2 选举Leader\n\n最简单最直观的方案是，所有Follower都在ZooKeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（ZooKeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。\n\n但是该方法会有3个问题：\n\n1.split-brain 这是由ZooKeeper的特性引起的，虽然ZooKeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致\n\n2.herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整\n\n3.ZooKeeper负载过重 每个Replica都要为此在ZooKeeper上注册一个Watch，当集群规模增加到几千个Partition时ZooKeeper负载会过重。\n\nKafka 0.8.*的Leader Election方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比ZooKeeper Queue的方式更高效）通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。\n\n## 2.0 Kafka 高可用\n\n### 2.1 Replication\n\n在Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与Kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。\n\n如果Producer使用同步模式则Producer会在尝试重新发送message.send.max.retries（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成数据的阻塞，后者会造成本应发往该Broker的数据的丢失。\n\n如果Producer使用异步模式，则Producer会尝试重新发送message.send.max.retries（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。同时，Kafka的Producer并未对异步模式提供callback接口。\n\n由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。\n\n### 2.1.2 Leader Election\n\n引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。\n\n因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。\n\n## 3.0 HA 相关ZooKeeper结构\n\n![](/images/kafka/kafka_3_2.png)\n\n### 3.1 admin\n\n该目录下znode只有在有相关操作时才会存在，操作结束时会将其删除\n\n/admin/reassign_partitions用于将一些Partition分配到不同的broker集合上。对于每个待重新分配的Partition，Kafka会在该znode上存储其所有的Replica和相应的Broker id。该znode由管理进程创建并且一旦重新分配成功它将会被自动移除。\n\n### 3.2 broker\n\n即/brokers/ids/[brokerId]）存储“活着”的broker信息。\n\ntopic注册信息（/brokers/topics/[topic]），存储该topic的所有partition的所有replica所在的broker id，第一个replica即为preferred replica，对一个给定的partition，它在同一个broker上最多只有一个replica,因此broker id可作为replica id。\n\n### 3.3 controller\n\n/controller -> int (broker id of the controller)存储当前controller的信息\n\n/controller_epoch -> int (epoch)直接以整数形式存储controller epoch，而非像其它znode一样以JSON字符串形式存储。\n\n","slug":"kafka-3","published":1,"updated":"2021-07-08T02:05:24.179Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckqu9t2qh000by8va9wfbd0gb","content":"<h1 id=\"Apache-Kafka-是一个分布式流处理平台。\"><a href=\"#Apache-Kafka-是一个分布式流处理平台。\" class=\"headerlink\" title=\"Apache Kafka 是一个分布式流处理平台。\"></a><strong>Apache Kafka 是一个分布式流处理平台。</strong></h1><h2 id=\"1-0-Kafka-HA-设计\"><a href=\"#1-0-Kafka-HA-设计\" class=\"headerlink\" title=\"1.0 Kafka HA 设计\"></a>1.0 Kafka HA 设计</h2><h3 id=\"1-1-将Replica均匀分布到整个集群\"><a href=\"#1-1-将Replica均匀分布到整个集群\" class=\"headerlink\" title=\"1.1 将Replica均匀分布到整个集群\"></a>1.1 将Replica均匀分布到整个集群</h3><p>Kafka尽力把所有的Partition均匀分配到集群上是为了负载均衡。 一个典型的部署方式是一个Topic的Partition数量大于broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。</p>\n<h3 id=\"1-2-Data-Replication-副本策略\"><a href=\"#1-2-Data-Replication-副本策略\" class=\"headerlink\" title=\"1.2 Data Replication(副本策略)\"></a>1.2 Data Replication(副本策略)</h3><p>Kafka的高可靠性的保障来源于其健壮的副本（replication）策略。</p>\n<h4 id=\"1-2-1-消息传递同步策略\"><a href=\"#1-2-1-消息传递同步策略\" class=\"headerlink\" title=\"1.2.1 消息传递同步策略\"></a>1.2.1 消息传递同步策略</h4><p>producer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少，Producer只将该消息发送到该Partition的Leader。Leader会将消息写入本地log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。</p>\n<p>Kafka Replication的数据流如下图所示：</p>\n<p><img src=\"/images/kafka/kafka_3_1.png\"></p>\n<h4 id=\"1-2-2-选举Leader\"><a href=\"#1-2-2-选举Leader\" class=\"headerlink\" title=\"1.2.2 选举Leader\"></a>1.2.2 选举Leader</h4><p>最简单最直观的方案是，所有Follower都在ZooKeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（ZooKeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。</p>\n<p>但是该方法会有3个问题：</p>\n<p>1.split-brain 这是由ZooKeeper的特性引起的，虽然ZooKeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致</p>\n<p>2.herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整</p>\n<p>3.ZooKeeper负载过重 每个Replica都要为此在ZooKeeper上注册一个Watch，当集群规模增加到几千个Partition时ZooKeeper负载会过重。</p>\n<p>Kafka 0.8.*的Leader Election方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比ZooKeeper Queue的方式更高效）通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。</p>\n<h2 id=\"2-0-Kafka-高可用\"><a href=\"#2-0-Kafka-高可用\" class=\"headerlink\" title=\"2.0 Kafka 高可用\"></a>2.0 Kafka 高可用</h2><h3 id=\"2-1-Replication\"><a href=\"#2-1-Replication\" class=\"headerlink\" title=\"2.1 Replication\"></a>2.1 Replication</h3><p>在Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与Kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。</p>\n<p>如果Producer使用同步模式则Producer会在尝试重新发送message.send.max.retries（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成数据的阻塞，后者会造成本应发往该Broker的数据的丢失。</p>\n<p>如果Producer使用异步模式，则Producer会尝试重新发送message.send.max.retries（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。同时，Kafka的Producer并未对异步模式提供callback接口。</p>\n<p>由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。</p>\n<h3 id=\"2-1-2-Leader-Election\"><a href=\"#2-1-2-Leader-Election\" class=\"headerlink\" title=\"2.1.2 Leader Election\"></a>2.1.2 Leader Election</h3><p>引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。</p>\n<p>因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。</p>\n<h2 id=\"3-0-HA-相关ZooKeeper结构\"><a href=\"#3-0-HA-相关ZooKeeper结构\" class=\"headerlink\" title=\"3.0 HA 相关ZooKeeper结构\"></a>3.0 HA 相关ZooKeeper结构</h2><p><img src=\"/images/kafka/kafka_3_2.png\"></p>\n<h3 id=\"3-1-admin\"><a href=\"#3-1-admin\" class=\"headerlink\" title=\"3.1 admin\"></a>3.1 admin</h3><p>该目录下znode只有在有相关操作时才会存在，操作结束时会将其删除</p>\n<p>/admin/reassign_partitions用于将一些Partition分配到不同的broker集合上。对于每个待重新分配的Partition，Kafka会在该znode上存储其所有的Replica和相应的Broker id。该znode由管理进程创建并且一旦重新分配成功它将会被自动移除。</p>\n<h3 id=\"3-2-broker\"><a href=\"#3-2-broker\" class=\"headerlink\" title=\"3.2 broker\"></a>3.2 broker</h3><p>即/brokers/ids/[brokerId]）存储“活着”的broker信息。</p>\n<p>topic注册信息（/brokers/topics/[topic]），存储该topic的所有partition的所有replica所在的broker id，第一个replica即为preferred replica，对一个给定的partition，它在同一个broker上最多只有一个replica,因此broker id可作为replica id。</p>\n<h3 id=\"3-3-controller\"><a href=\"#3-3-controller\" class=\"headerlink\" title=\"3.3 controller\"></a>3.3 controller</h3><p>/controller -&gt; int (broker id of the controller)存储当前controller的信息</p>\n<p>/controller_epoch -&gt; int (epoch)直接以整数形式存储controller epoch，而非像其它znode一样以JSON字符串形式存储。</p>\n","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":"<h1 id=\"Apache-Kafka-是一个分布式流处理平台。\"><a href=\"#Apache-Kafka-是一个分布式流处理平台。\" class=\"headerlink\" title=\"Apache Kafka 是一个分布式流处理平台。\"></a><strong>Apache Kafka 是一个分布式流处理平台。</strong></h1><h2 id=\"1-0-Kafka-HA-设计\"><a href=\"#1-0-Kafka-HA-设计\" class=\"headerlink\" title=\"1.0 Kafka HA 设计\"></a>1.0 Kafka HA 设计</h2><h3 id=\"1-1-将Replica均匀分布到整个集群\"><a href=\"#1-1-将Replica均匀分布到整个集群\" class=\"headerlink\" title=\"1.1 将Replica均匀分布到整个集群\"></a>1.1 将Replica均匀分布到整个集群</h3><p>Kafka尽力把所有的Partition均匀分配到集群上是为了负载均衡。 一个典型的部署方式是一个Topic的Partition数量大于broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。</p>\n<h3 id=\"1-2-Data-Replication-副本策略\"><a href=\"#1-2-Data-Replication-副本策略\" class=\"headerlink\" title=\"1.2 Data Replication(副本策略)\"></a>1.2 Data Replication(副本策略)</h3><p>Kafka的高可靠性的保障来源于其健壮的副本（replication）策略。</p>\n<h4 id=\"1-2-1-消息传递同步策略\"><a href=\"#1-2-1-消息传递同步策略\" class=\"headerlink\" title=\"1.2.1 消息传递同步策略\"></a>1.2.1 消息传递同步策略</h4><p>producer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少，Producer只将该消息发送到该Partition的Leader。Leader会将消息写入本地log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。</p>\n<p>Kafka Replication的数据流如下图所示：</p>\n<p><img src=\"/images/kafka/kafka_3_1.png\"></p>\n<h4 id=\"1-2-2-选举Leader\"><a href=\"#1-2-2-选举Leader\" class=\"headerlink\" title=\"1.2.2 选举Leader\"></a>1.2.2 选举Leader</h4><p>最简单最直观的方案是，所有Follower都在ZooKeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（ZooKeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。</p>\n<p>但是该方法会有3个问题：</p>\n<p>1.split-brain 这是由ZooKeeper的特性引起的，虽然ZooKeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致</p>\n<p>2.herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整</p>\n<p>3.ZooKeeper负载过重 每个Replica都要为此在ZooKeeper上注册一个Watch，当集群规模增加到几千个Partition时ZooKeeper负载会过重。</p>\n<p>Kafka 0.8.*的Leader Election方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比ZooKeeper Queue的方式更高效）通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。</p>\n<h2 id=\"2-0-Kafka-高可用\"><a href=\"#2-0-Kafka-高可用\" class=\"headerlink\" title=\"2.0 Kafka 高可用\"></a>2.0 Kafka 高可用</h2><h3 id=\"2-1-Replication\"><a href=\"#2-1-Replication\" class=\"headerlink\" title=\"2.1 Replication\"></a>2.1 Replication</h3><p>在Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与Kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。</p>\n<p>如果Producer使用同步模式则Producer会在尝试重新发送message.send.max.retries（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成数据的阻塞，后者会造成本应发往该Broker的数据的丢失。</p>\n<p>如果Producer使用异步模式，则Producer会尝试重新发送message.send.max.retries（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。同时，Kafka的Producer并未对异步模式提供callback接口。</p>\n<p>由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。</p>\n<h3 id=\"2-1-2-Leader-Election\"><a href=\"#2-1-2-Leader-Election\" class=\"headerlink\" title=\"2.1.2 Leader Election\"></a>2.1.2 Leader Election</h3><p>引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replication之间选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。</p>\n<p>因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。</p>\n<h2 id=\"3-0-HA-相关ZooKeeper结构\"><a href=\"#3-0-HA-相关ZooKeeper结构\" class=\"headerlink\" title=\"3.0 HA 相关ZooKeeper结构\"></a>3.0 HA 相关ZooKeeper结构</h2><p><img src=\"/images/kafka/kafka_3_2.png\"></p>\n<h3 id=\"3-1-admin\"><a href=\"#3-1-admin\" class=\"headerlink\" title=\"3.1 admin\"></a>3.1 admin</h3><p>该目录下znode只有在有相关操作时才会存在，操作结束时会将其删除</p>\n<p>/admin/reassign_partitions用于将一些Partition分配到不同的broker集合上。对于每个待重新分配的Partition，Kafka会在该znode上存储其所有的Replica和相应的Broker id。该znode由管理进程创建并且一旦重新分配成功它将会被自动移除。</p>\n<h3 id=\"3-2-broker\"><a href=\"#3-2-broker\" class=\"headerlink\" title=\"3.2 broker\"></a>3.2 broker</h3><p>即/brokers/ids/[brokerId]）存储“活着”的broker信息。</p>\n<p>topic注册信息（/brokers/topics/[topic]），存储该topic的所有partition的所有replica所在的broker id，第一个replica即为preferred replica，对一个给定的partition，它在同一个broker上最多只有一个replica,因此broker id可作为replica id。</p>\n<h3 id=\"3-3-controller\"><a href=\"#3-3-controller\" class=\"headerlink\" title=\"3.3 controller\"></a>3.3 controller</h3><p>/controller -&gt; int (broker id of the controller)存储当前controller的信息</p>\n<p>/controller_epoch -&gt; int (epoch)直接以整数形式存储controller epoch，而非像其它znode一样以JSON字符串形式存储。</p>\n"},{"title":"厦门日记","date":"2021-07-01T07:51:20.000Z","copyright":false,"image":"/images/welcome_light.jpg","_content":"这是测试一下\nwelcome_light\n## 第一节\nabc\n\n## 第二节\n\nbcd","source":"_posts/xiamen_diary.md","raw":"---\ntitle: 厦门日记\ndate: 2021-07-01 15:51:20\ntags:\ncategories: 日记\ncopyright: false\nimage: /images/welcome_light.jpg\n---\n这是测试一下\nwelcome_light\n## 第一节\nabc\n\n## 第二节\n\nbcd","slug":"xiamen_diary","published":1,"updated":"2021-07-08T01:04:23.724Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckqu9t2qi000cy8va9oj0b5wl","content":"<p>这是测试一下<br>welcome_light</p>\n<h2 id=\"第一节\"><a href=\"#第一节\" class=\"headerlink\" title=\"第一节\"></a>第一节</h2><p>abc</p>\n<h2 id=\"第二节\"><a href=\"#第二节\" class=\"headerlink\" title=\"第二节\"></a>第二节</h2><p>bcd</p>\n","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":"<p>这是测试一下<br>welcome_light</p>\n<h2 id=\"第一节\"><a href=\"#第一节\" class=\"headerlink\" title=\"第一节\"></a>第一节</h2><p>abc</p>\n<h2 id=\"第二节\"><a href=\"#第二节\" class=\"headerlink\" title=\"第二节\"></a>第二节</h2><p>bcd</p>\n"},{"title":"Kafka(一)","date":"2021-07-01T08:38:09.000Z","keywords":"Kafka,kafka","_content":"# **Apache Kafka 是一个分布式流处理平台。**\n\n## 1.0 介绍\n\nkafka 作为一个集群，运行在一台或者多台服务器上，它是通过topic对存储的流数据进行分类。每条记录中包含一个key,一个value和一个timestamp(时间戳)。\n\nKafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。\n\nkafka有四个核心的API：\n- Producer API允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。\n- Consumer API允许一个应用程序订阅一个或者多个topic,并且对发布给他们的流式数据进行处理。\n- Streams API允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后产生一个输出流到一个或者多个topic中去，在输入输出流中进行有效的转换。\n- Connector API允许构建并运行可重用的生产者或者消费者，将Kafka Topic连接到已经存在的应用程序或者数据系统。\n![](/images/kafka/kafka-apis.png)\n\n### 1.1 相关术语\n\n#### 1.1.1 broker\n\nKafka 集群包含一个或多个服务器，服务器节点称为broker。\n\nbroker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。\n\n如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。\n\n如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。\n\n#### 1.1.2 Topic\n\n每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n类似于数据库的表名\n\n#### 1.1.3 Partition\n\ntopic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。\n\n#### 1.1.4 Producer\n\n生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。\n\n#### 1.1.5 Consumer\n\n消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。\n\n#### 1.1.6 Consumer Group\n\n每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\n#### 1.1.7 Leader\n\n每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。\n\n#### 1.1.8 Follower\n\nFollower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。\n\n### 1.2 Topics和日志\nTopic 是数据主题，是数据记录发布的地方，可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费之来订阅它的数据。\n\n每一个topic，Kafka集群会维持一个分区日志。\n\n![](/images/kafka/log_anatomy.png)\n\n每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id来表示顺序，我们称为offset,offset用来唯一的标识分区中的每一条数据。\n\nkafka的性能和数据大小无关，所以长时间存储数据没什么问题。\n\n日志中的partition分区有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可以有多个分区，因此可以处理无限量的数据。第二，可以作为并行的单元集。\n\n### 1.3 分布式\n\n日志的分区partition分布在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。\n\n每个分区都有一台server作为“leader”， 0台或者多台server作为follers.leader server处理一切对partition分区的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers中的一台服务器会自动成为新的leader。每台server都会成为某些分区的leader和某些分区的follower，因此集群的负载是平衡的。\n\n### 1.4 生产者\n\n生产者可以将数据发布到所选择的topic(主题)中。生产者负责记录分配到topic中的某个partition分区中。可以使用循环的方式来简单地实现负载均衡。\n\n### 1.5 消费者\n\n消费者使用一个消费组名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的消费者实例。消费者实例可以分布在多个进程中或者多个机器上。\n\n如果所有的消费者实例在同一消费组中，消费记录会负载均衡到每一个消费者实例。\n\n如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程。\n![](/images/kafka/consumer_groups.png)\n\n如图，这个Kafka集群有两台server，四个分区和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。\n\n通常情况下，每个topic都会有一些消费组，一个消费组对应一个“逻辑订阅者”。 一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个进程。\n\n在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费者组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些partition分区；如果一个实例消失，拥有的分区将被分发至剩余的实例。\n\nKafka只保证分区内记录是有序的，不保证主题中不同分区的顺序。\n\n### 1.6 Kafka作为存储系统\n\n数据写入Kafka后被写入到磁盘，并且备份以便容错，直到完全备份，Kafka才让生产者认为完成写入，即使写入失败kafka也会确保继续写入Kafka使用磁盘结构，具有很好的扩展性。\n\nKafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。\n\n### 1.7 Kafka用作流处理\n\nKafka流处理不仅用来读写和存储流式数据，最终目的是为了能够进行实时的流处理。在Kafka中，流处理不断地从输入的topic获取流数据，处理数据后，在不断生产数据到输出的topic中去。\n\n简单数据处理可以使用生产者和消费者的API。对于复杂的数据变换，Kafka提供了Streams　API。Stream　API允许应用做一些复杂的处理，比如将流数据聚合或者join。\n\n这一功能有助于解决以下这种应用程序面临的问题：处理无序数据，当消费端代码变更后重新处理输入，执行有状态计算等。\n\nStreams API建立在Kafka的核心之上：它使用Producer和Consumer API作为输入，使用Kafka进行有状态的存储，并在流处理实例之间使用相同的消费组机制来实现容错。\n\n### 1.8 批处理\n\nKafka将消息、存储和流处理结合起来，通过组合存储和低延迟订阅，流式应用程序可以以同样的方式处理过去和未来的数据。\n\n同样，作为流数据管道，能够订阅实时事件使得Kafka具有非常低的延迟；同时Kafka还具有可靠存储数据的特性，可用来存储重要的支付数据，或者与离线系统进行交互，系统可间歇性加载数据，也可在停机维护后再次加载数据。流处理功能使得数据可以在到达时转换数据。\n\n\n## 2.0 基本教程\n\n如果是windows平台，使用bin\\windows\\而不是bin/，并将脚本扩展名改为.bat\n\n### Step 1: 下载\n\n[下载](https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz)相关版本并解压缩。\n\n```> cd kafka```\n\n### Step 2: 启动服务器\n\nKafka使用[ZooKeeper](https://zookeeper.apache.org/),如果你还没有ZooKeeper服务器。\n\n```> bin/zookeeper-server-start.sh config/zookeeper.properties```\n\n```[2021-07-2 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)```\n\n开始启动Kafka服务器：\n\n```> bin/kafka-server-start.sh config/server.properties```\n\n### Step 3: 创建一个topic\n\n创建一个名为\"test\"的topic，有一个分区和一个副本：\n\n```> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test```\n\n现在运行list命令来查看这个topic:\n\n```> bin/kafka-topics.sh --list --zookeeper localhost:2181```\n\n```test```\n\n### Step 4: 发送消息\n\nKafka自带一个命令行客户端，它从文件或标准输入中获取输入，将其作为message发送到Kafka集群。默认情况下，每行将作为单独的message发送。\n\n运行producer,然后在控制台输入一些消息已发送到服务器。\n\n```> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test```\n\n```This is a message```\n\n### Step 5: 启动一个consumer\n\nKafka有一个命令行consumer，将消息转储到标准输出。\n\n ```> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning```\n\n```This is a message```\n\n### Step 6: 设置多个代理集群\n\n首先，为每个代理创建一个配置文件（在windows上使用copy命令来代替）：\n\n```> cp config/server.properties config/server-1.properties```\n\n```> cp config/server.properties config/server-2.properties```\n\n### Step 7: 使用Kafka Connect来导入/导出数据\n\nKafka Connect是Kafka的一个工具，它可以将数据导入和导出到Kafka。它是一种可扩展工具，通过运行connectors（连接器）， 使用自定义逻辑来实现与外部系统的交互。 在本文中，我们将看到如何使用简单的connectors来运行Kafka Connect，这些connectors 将文件中的数据导入到Kafka topic中，并从中导出数据到一个文件。\n\n首先，创建一个测试文件：\n\n```> echo -e \"foo\\nbar\" > test.txt```\n\n在Windows系统使用：\n\n```> echo foo> test.txt```\n\n```> echo bar>> test.txt```\n\n接下来，我们将启动两个standalone（独立）运行的连接器，这意味着它们各自运行在一个单独的本地专用 进程上。 我们提供三个配置文件。首先是Kafka Connect的配置文件，包含常用的配置，如Kafka brokers连接方式和数据的序列化格式。 其余的配置文件均指定一个要创建的连接器。这些文件包括连接器的唯一名称，类的实例，以及其他连接器所需的配置。\n\n```> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties```\n\n这些包含在Kafka中的示例配置文件使用您之前启动的默认本地群集配置，并创建两个连接器： 第一个是源连接器，用于从输入文件读取行，并将其输入到 Kafka topic。 第二个是接收器连接器，它从Kafka topic中读取消息，并在输出文件中生成一行。\n\n在启动过程中，你会看到一些日志消息，包括一些连接器正在实例化的指示。 一旦Kafka Connect进程启动，源连接器就开始从 test.txt 读取行并且 将它们生产到主题 connect-test 中，同时接收器连接器也开始从主题 connect-test 中读取消息， 并将它们写入文件 test.sink.txt 中。我们可以通过检查输出文件的内容来验证数据是否已通过整个pipeline进行交付：\n\n```> more test.sink.txt```\n\n```foo```\n\n```bar```\n\n数据存储在Kafka topic connect-test 中，因此我们也可以运行一个console consumer（控制台消费者）来查看 topic 中的数据（或使用custom consumer（自定义消费者）代码进行处理）：\n\n```> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning```\n\n```{\"schema\":{\"type\":\"string\",\"optional\":false},\"payload\":\"foo\"}```\n\n```{\"schema\":{\"type\":\"string\",\"optional\":false},\"payload\":\"bar\"}```\n\n```...```\n\n连接器一直在处理数据，所以我们可以将数据添加到文件中，并看到它在pipeline 中移动：\n\n```> echo Another line>> test.txt```\n\n### Step 8: 使用Kafka Streams来处理数据\n\nKafka Streams是用于构建实时关键应用程序和微服务的客户端库，输入与输出数据存储在Kafka集群中。 Kafka Streams把客户端能够轻便地编写部署标准Java和Scala应用程序的优势与Kafka服务器端集群技术相结合，使这些应用程序具有高度伸缩性、弹性、容错性、分布式等特性。\n\n## 3.0 使用案例\n\n### 3.1 消息\n\nKafka很好的替代了传统的message broker（消息代理）。Message brokers可用于各种场合（如将数据生成器与数据处理解耦，缓冲未处理的消息等）。与大多数消息系统相比，Kafka拥有更好的吞吐量、内置分区、具有复制和容错功能，这使他成为一个非常理想的大型消息处理应用。\n\n### 3.2 跟踪网站活动\n\nKafka的初始用例是将用户活动跟踪管道重建为一组实时发布-订阅源。这意味着网站活动（浏览网页、搜索或其他的用户操作）将被发布到中心topic，其中每个活动类型有一个topic。这些订阅源提供一系列用例，包括实时处理、实时监视、对加载到Hadoop或离线数据仓库系统的数据进行离线处理和报告等。\n\n### 3.3 度量\n\nKafka通常用于监控数据。这涉及到从分布式应用程序中汇总数据，然后生成可操作的集中数据源。\n\n### 3.4 日志聚合\n\n日志聚合系统通常从服务器收集物理日志文件，并将其置于一个中心系统（可能是文件服务器或HDFS）进行处理。Kafka从这些日志文件中提取信息，并将其抽象为一个更加清晰的消息流。这样可以实现更低的延迟处理且易于支持多个数据源及分布式数据的消耗。\n\n### 3.5 流处理\n\nKafka用户通过管道来处理数据，有多个阶段： 从Kafka topic中消费原始输入数据，然后聚合，修饰或通过其他方式转化为新的topic， 以供进一步消费或处理。Kafka Streams是一个轻量但功能强大的流处理库。\n\n### 3.6 采集日志\n\n[Event sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)是一种应用程序设计风格，按时间来记录状态的更改。 Kafka 可以存储非常多的日志数据，为基于 event sourcing 的应用程序提供强有力的支持。\n\n### 3.7 提交日志\n\nKafka 可以从外部为分布式系统提供日志提交功能。 日志有助于记录节点和行为间的数据，采用重新同步机制可以从失败节点恢复数据。 Kafka的日志压缩 功能支持这一用法。\n\n[有关Kafka提供的保证、API和功能的更多信息，请查看相关文档。](https://kafka.apache.org/documentation/#gettingStarted)","source":"_posts/kafka-1.md","raw":"---\ntitle: Kafka(一)\ndate: 2021-07-01 16:38:09\ntags: Kafka\ncategories: 技术\nkeywords: Kafka,kafka\n---\n# **Apache Kafka 是一个分布式流处理平台。**\n\n## 1.0 介绍\n\nkafka 作为一个集群，运行在一台或者多台服务器上，它是通过topic对存储的流数据进行分类。每条记录中包含一个key,一个value和一个timestamp(时间戳)。\n\nKafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。\n\nkafka有四个核心的API：\n- Producer API允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。\n- Consumer API允许一个应用程序订阅一个或者多个topic,并且对发布给他们的流式数据进行处理。\n- Streams API允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后产生一个输出流到一个或者多个topic中去，在输入输出流中进行有效的转换。\n- Connector API允许构建并运行可重用的生产者或者消费者，将Kafka Topic连接到已经存在的应用程序或者数据系统。\n![](/images/kafka/kafka-apis.png)\n\n### 1.1 相关术语\n\n#### 1.1.1 broker\n\nKafka 集群包含一个或多个服务器，服务器节点称为broker。\n\nbroker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。\n\n如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。\n\n如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。\n\n#### 1.1.2 Topic\n\n每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\n\n类似于数据库的表名\n\n#### 1.1.3 Partition\n\ntopic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。\n\n#### 1.1.4 Producer\n\n生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。\n\n#### 1.1.5 Consumer\n\n消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。\n\n#### 1.1.6 Consumer Group\n\n每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。\n\n#### 1.1.7 Leader\n\n每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。\n\n#### 1.1.8 Follower\n\nFollower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。\n\n### 1.2 Topics和日志\nTopic 是数据主题，是数据记录发布的地方，可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费之来订阅它的数据。\n\n每一个topic，Kafka集群会维持一个分区日志。\n\n![](/images/kafka/log_anatomy.png)\n\n每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id来表示顺序，我们称为offset,offset用来唯一的标识分区中的每一条数据。\n\nkafka的性能和数据大小无关，所以长时间存储数据没什么问题。\n\n日志中的partition分区有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可以有多个分区，因此可以处理无限量的数据。第二，可以作为并行的单元集。\n\n### 1.3 分布式\n\n日志的分区partition分布在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。\n\n每个分区都有一台server作为“leader”， 0台或者多台server作为follers.leader server处理一切对partition分区的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers中的一台服务器会自动成为新的leader。每台server都会成为某些分区的leader和某些分区的follower，因此集群的负载是平衡的。\n\n### 1.4 生产者\n\n生产者可以将数据发布到所选择的topic(主题)中。生产者负责记录分配到topic中的某个partition分区中。可以使用循环的方式来简单地实现负载均衡。\n\n### 1.5 消费者\n\n消费者使用一个消费组名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的消费者实例。消费者实例可以分布在多个进程中或者多个机器上。\n\n如果所有的消费者实例在同一消费组中，消费记录会负载均衡到每一个消费者实例。\n\n如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程。\n![](/images/kafka/consumer_groups.png)\n\n如图，这个Kafka集群有两台server，四个分区和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。\n\n通常情况下，每个topic都会有一些消费组，一个消费组对应一个“逻辑订阅者”。 一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个进程。\n\n在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费者组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些partition分区；如果一个实例消失，拥有的分区将被分发至剩余的实例。\n\nKafka只保证分区内记录是有序的，不保证主题中不同分区的顺序。\n\n### 1.6 Kafka作为存储系统\n\n数据写入Kafka后被写入到磁盘，并且备份以便容错，直到完全备份，Kafka才让生产者认为完成写入，即使写入失败kafka也会确保继续写入Kafka使用磁盘结构，具有很好的扩展性。\n\nKafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。\n\n### 1.7 Kafka用作流处理\n\nKafka流处理不仅用来读写和存储流式数据，最终目的是为了能够进行实时的流处理。在Kafka中，流处理不断地从输入的topic获取流数据，处理数据后，在不断生产数据到输出的topic中去。\n\n简单数据处理可以使用生产者和消费者的API。对于复杂的数据变换，Kafka提供了Streams　API。Stream　API允许应用做一些复杂的处理，比如将流数据聚合或者join。\n\n这一功能有助于解决以下这种应用程序面临的问题：处理无序数据，当消费端代码变更后重新处理输入，执行有状态计算等。\n\nStreams API建立在Kafka的核心之上：它使用Producer和Consumer API作为输入，使用Kafka进行有状态的存储，并在流处理实例之间使用相同的消费组机制来实现容错。\n\n### 1.8 批处理\n\nKafka将消息、存储和流处理结合起来，通过组合存储和低延迟订阅，流式应用程序可以以同样的方式处理过去和未来的数据。\n\n同样，作为流数据管道，能够订阅实时事件使得Kafka具有非常低的延迟；同时Kafka还具有可靠存储数据的特性，可用来存储重要的支付数据，或者与离线系统进行交互，系统可间歇性加载数据，也可在停机维护后再次加载数据。流处理功能使得数据可以在到达时转换数据。\n\n\n## 2.0 基本教程\n\n如果是windows平台，使用bin\\windows\\而不是bin/，并将脚本扩展名改为.bat\n\n### Step 1: 下载\n\n[下载](https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz)相关版本并解压缩。\n\n```> cd kafka```\n\n### Step 2: 启动服务器\n\nKafka使用[ZooKeeper](https://zookeeper.apache.org/),如果你还没有ZooKeeper服务器。\n\n```> bin/zookeeper-server-start.sh config/zookeeper.properties```\n\n```[2021-07-2 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)```\n\n开始启动Kafka服务器：\n\n```> bin/kafka-server-start.sh config/server.properties```\n\n### Step 3: 创建一个topic\n\n创建一个名为\"test\"的topic，有一个分区和一个副本：\n\n```> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test```\n\n现在运行list命令来查看这个topic:\n\n```> bin/kafka-topics.sh --list --zookeeper localhost:2181```\n\n```test```\n\n### Step 4: 发送消息\n\nKafka自带一个命令行客户端，它从文件或标准输入中获取输入，将其作为message发送到Kafka集群。默认情况下，每行将作为单独的message发送。\n\n运行producer,然后在控制台输入一些消息已发送到服务器。\n\n```> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test```\n\n```This is a message```\n\n### Step 5: 启动一个consumer\n\nKafka有一个命令行consumer，将消息转储到标准输出。\n\n ```> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning```\n\n```This is a message```\n\n### Step 6: 设置多个代理集群\n\n首先，为每个代理创建一个配置文件（在windows上使用copy命令来代替）：\n\n```> cp config/server.properties config/server-1.properties```\n\n```> cp config/server.properties config/server-2.properties```\n\n### Step 7: 使用Kafka Connect来导入/导出数据\n\nKafka Connect是Kafka的一个工具，它可以将数据导入和导出到Kafka。它是一种可扩展工具，通过运行connectors（连接器）， 使用自定义逻辑来实现与外部系统的交互。 在本文中，我们将看到如何使用简单的connectors来运行Kafka Connect，这些connectors 将文件中的数据导入到Kafka topic中，并从中导出数据到一个文件。\n\n首先，创建一个测试文件：\n\n```> echo -e \"foo\\nbar\" > test.txt```\n\n在Windows系统使用：\n\n```> echo foo> test.txt```\n\n```> echo bar>> test.txt```\n\n接下来，我们将启动两个standalone（独立）运行的连接器，这意味着它们各自运行在一个单独的本地专用 进程上。 我们提供三个配置文件。首先是Kafka Connect的配置文件，包含常用的配置，如Kafka brokers连接方式和数据的序列化格式。 其余的配置文件均指定一个要创建的连接器。这些文件包括连接器的唯一名称，类的实例，以及其他连接器所需的配置。\n\n```> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties```\n\n这些包含在Kafka中的示例配置文件使用您之前启动的默认本地群集配置，并创建两个连接器： 第一个是源连接器，用于从输入文件读取行，并将其输入到 Kafka topic。 第二个是接收器连接器，它从Kafka topic中读取消息，并在输出文件中生成一行。\n\n在启动过程中，你会看到一些日志消息，包括一些连接器正在实例化的指示。 一旦Kafka Connect进程启动，源连接器就开始从 test.txt 读取行并且 将它们生产到主题 connect-test 中，同时接收器连接器也开始从主题 connect-test 中读取消息， 并将它们写入文件 test.sink.txt 中。我们可以通过检查输出文件的内容来验证数据是否已通过整个pipeline进行交付：\n\n```> more test.sink.txt```\n\n```foo```\n\n```bar```\n\n数据存储在Kafka topic connect-test 中，因此我们也可以运行一个console consumer（控制台消费者）来查看 topic 中的数据（或使用custom consumer（自定义消费者）代码进行处理）：\n\n```> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning```\n\n```{\"schema\":{\"type\":\"string\",\"optional\":false},\"payload\":\"foo\"}```\n\n```{\"schema\":{\"type\":\"string\",\"optional\":false},\"payload\":\"bar\"}```\n\n```...```\n\n连接器一直在处理数据，所以我们可以将数据添加到文件中，并看到它在pipeline 中移动：\n\n```> echo Another line>> test.txt```\n\n### Step 8: 使用Kafka Streams来处理数据\n\nKafka Streams是用于构建实时关键应用程序和微服务的客户端库，输入与输出数据存储在Kafka集群中。 Kafka Streams把客户端能够轻便地编写部署标准Java和Scala应用程序的优势与Kafka服务器端集群技术相结合，使这些应用程序具有高度伸缩性、弹性、容错性、分布式等特性。\n\n## 3.0 使用案例\n\n### 3.1 消息\n\nKafka很好的替代了传统的message broker（消息代理）。Message brokers可用于各种场合（如将数据生成器与数据处理解耦，缓冲未处理的消息等）。与大多数消息系统相比，Kafka拥有更好的吞吐量、内置分区、具有复制和容错功能，这使他成为一个非常理想的大型消息处理应用。\n\n### 3.2 跟踪网站活动\n\nKafka的初始用例是将用户活动跟踪管道重建为一组实时发布-订阅源。这意味着网站活动（浏览网页、搜索或其他的用户操作）将被发布到中心topic，其中每个活动类型有一个topic。这些订阅源提供一系列用例，包括实时处理、实时监视、对加载到Hadoop或离线数据仓库系统的数据进行离线处理和报告等。\n\n### 3.3 度量\n\nKafka通常用于监控数据。这涉及到从分布式应用程序中汇总数据，然后生成可操作的集中数据源。\n\n### 3.4 日志聚合\n\n日志聚合系统通常从服务器收集物理日志文件，并将其置于一个中心系统（可能是文件服务器或HDFS）进行处理。Kafka从这些日志文件中提取信息，并将其抽象为一个更加清晰的消息流。这样可以实现更低的延迟处理且易于支持多个数据源及分布式数据的消耗。\n\n### 3.5 流处理\n\nKafka用户通过管道来处理数据，有多个阶段： 从Kafka topic中消费原始输入数据，然后聚合，修饰或通过其他方式转化为新的topic， 以供进一步消费或处理。Kafka Streams是一个轻量但功能强大的流处理库。\n\n### 3.6 采集日志\n\n[Event sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)是一种应用程序设计风格，按时间来记录状态的更改。 Kafka 可以存储非常多的日志数据，为基于 event sourcing 的应用程序提供强有力的支持。\n\n### 3.7 提交日志\n\nKafka 可以从外部为分布式系统提供日志提交功能。 日志有助于记录节点和行为间的数据，采用重新同步机制可以从失败节点恢复数据。 Kafka的日志压缩 功能支持这一用法。\n\n[有关Kafka提供的保证、API和功能的更多信息，请查看相关文档。](https://kafka.apache.org/documentation/#gettingStarted)","slug":"kafka-1","published":1,"updated":"2021-07-08T01:04:23.723Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckqu9t2ql000jy8va9ihacu3u","content":"<h1 id=\"Apache-Kafka-是一个分布式流处理平台。\"><a href=\"#Apache-Kafka-是一个分布式流处理平台。\" class=\"headerlink\" title=\"Apache Kafka 是一个分布式流处理平台。\"></a><strong>Apache Kafka 是一个分布式流处理平台。</strong></h1><h2 id=\"1-0-介绍\"><a href=\"#1-0-介绍\" class=\"headerlink\" title=\"1.0 介绍\"></a>1.0 介绍</h2><p>kafka 作为一个集群，运行在一台或者多台服务器上，它是通过topic对存储的流数据进行分类。每条记录中包含一个key,一个value和一个timestamp(时间戳)。</p>\n<p>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p>\n<p>kafka有四个核心的API：</p>\n<ul>\n<li>Producer API允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。</li>\n<li>Consumer API允许一个应用程序订阅一个或者多个topic,并且对发布给他们的流式数据进行处理。</li>\n<li>Streams API允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后产生一个输出流到一个或者多个topic中去，在输入输出流中进行有效的转换。</li>\n<li>Connector API允许构建并运行可重用的生产者或者消费者，将Kafka Topic连接到已经存在的应用程序或者数据系统。<br><img src=\"/images/kafka/kafka-apis.png\"></li>\n</ul>\n<h3 id=\"1-1-相关术语\"><a href=\"#1-1-相关术语\" class=\"headerlink\" title=\"1.1 相关术语\"></a>1.1 相关术语</h3><h4 id=\"1-1-1-broker\"><a href=\"#1-1-1-broker\" class=\"headerlink\" title=\"1.1.1 broker\"></a>1.1.1 broker</h4><p>Kafka 集群包含一个或多个服务器，服务器节点称为broker。</p>\n<p>broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。</p>\n<p>如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</p>\n<p>如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</p>\n<h4 id=\"1-1-2-Topic\"><a href=\"#1-1-2-Topic\" class=\"headerlink\" title=\"1.1.2 Topic\"></a>1.1.2 Topic</h4><p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>\n<p>类似于数据库的表名</p>\n<h4 id=\"1-1-3-Partition\"><a href=\"#1-1-3-Partition\" class=\"headerlink\" title=\"1.1.3 Partition\"></a>1.1.3 Partition</h4><p>topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</p>\n<h4 id=\"1-1-4-Producer\"><a href=\"#1-1-4-Producer\" class=\"headerlink\" title=\"1.1.4 Producer\"></a>1.1.4 Producer</h4><p>生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。</p>\n<h4 id=\"1-1-5-Consumer\"><a href=\"#1-1-5-Consumer\" class=\"headerlink\" title=\"1.1.5 Consumer\"></a>1.1.5 Consumer</h4><p>消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。</p>\n<h4 id=\"1-1-6-Consumer-Group\"><a href=\"#1-1-6-Consumer-Group\" class=\"headerlink\" title=\"1.1.6 Consumer Group\"></a>1.1.6 Consumer Group</h4><p>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</p>\n<h4 id=\"1-1-7-Leader\"><a href=\"#1-1-7-Leader\" class=\"headerlink\" title=\"1.1.7 Leader\"></a>1.1.7 Leader</h4><p>每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。</p>\n<h4 id=\"1-1-8-Follower\"><a href=\"#1-1-8-Follower\" class=\"headerlink\" title=\"1.1.8 Follower\"></a>1.1.8 Follower</h4><p>Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。</p>\n<h3 id=\"1-2-Topics和日志\"><a href=\"#1-2-Topics和日志\" class=\"headerlink\" title=\"1.2 Topics和日志\"></a>1.2 Topics和日志</h3><p>Topic 是数据主题，是数据记录发布的地方，可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费之来订阅它的数据。</p>\n<p>每一个topic，Kafka集群会维持一个分区日志。</p>\n<p><img src=\"/images/kafka/log_anatomy.png\"></p>\n<p>每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id来表示顺序，我们称为offset,offset用来唯一的标识分区中的每一条数据。</p>\n<p>kafka的性能和数据大小无关，所以长时间存储数据没什么问题。</p>\n<p>日志中的partition分区有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可以有多个分区，因此可以处理无限量的数据。第二，可以作为并行的单元集。</p>\n<h3 id=\"1-3-分布式\"><a href=\"#1-3-分布式\" class=\"headerlink\" title=\"1.3 分布式\"></a>1.3 分布式</h3><p>日志的分区partition分布在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。</p>\n<p>每个分区都有一台server作为“leader”， 0台或者多台server作为follers.leader server处理一切对partition分区的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers中的一台服务器会自动成为新的leader。每台server都会成为某些分区的leader和某些分区的follower，因此集群的负载是平衡的。</p>\n<h3 id=\"1-4-生产者\"><a href=\"#1-4-生产者\" class=\"headerlink\" title=\"1.4 生产者\"></a>1.4 生产者</h3><p>生产者可以将数据发布到所选择的topic(主题)中。生产者负责记录分配到topic中的某个partition分区中。可以使用循环的方式来简单地实现负载均衡。</p>\n<h3 id=\"1-5-消费者\"><a href=\"#1-5-消费者\" class=\"headerlink\" title=\"1.5 消费者\"></a>1.5 消费者</h3><p>消费者使用一个消费组名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的消费者实例。消费者实例可以分布在多个进程中或者多个机器上。</p>\n<p>如果所有的消费者实例在同一消费组中，消费记录会负载均衡到每一个消费者实例。</p>\n<p>如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程。<br><img src=\"/images/kafka/consumer_groups.png\"></p>\n<p>如图，这个Kafka集群有两台server，四个分区和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。</p>\n<p>通常情况下，每个topic都会有一些消费组，一个消费组对应一个“逻辑订阅者”。 一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个进程。</p>\n<p>在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费者组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些partition分区；如果一个实例消失，拥有的分区将被分发至剩余的实例。</p>\n<p>Kafka只保证分区内记录是有序的，不保证主题中不同分区的顺序。</p>\n<h3 id=\"1-6-Kafka作为存储系统\"><a href=\"#1-6-Kafka作为存储系统\" class=\"headerlink\" title=\"1.6 Kafka作为存储系统\"></a>1.6 Kafka作为存储系统</h3><p>数据写入Kafka后被写入到磁盘，并且备份以便容错，直到完全备份，Kafka才让生产者认为完成写入，即使写入失败kafka也会确保继续写入Kafka使用磁盘结构，具有很好的扩展性。</p>\n<p>Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。</p>\n<h3 id=\"1-7-Kafka用作流处理\"><a href=\"#1-7-Kafka用作流处理\" class=\"headerlink\" title=\"1.7 Kafka用作流处理\"></a>1.7 Kafka用作流处理</h3><p>Kafka流处理不仅用来读写和存储流式数据，最终目的是为了能够进行实时的流处理。在Kafka中，流处理不断地从输入的topic获取流数据，处理数据后，在不断生产数据到输出的topic中去。</p>\n<p>简单数据处理可以使用生产者和消费者的API。对于复杂的数据变换，Kafka提供了Streams　API。Stream　API允许应用做一些复杂的处理，比如将流数据聚合或者join。</p>\n<p>这一功能有助于解决以下这种应用程序面临的问题：处理无序数据，当消费端代码变更后重新处理输入，执行有状态计算等。</p>\n<p>Streams API建立在Kafka的核心之上：它使用Producer和Consumer API作为输入，使用Kafka进行有状态的存储，并在流处理实例之间使用相同的消费组机制来实现容错。</p>\n<h3 id=\"1-8-批处理\"><a href=\"#1-8-批处理\" class=\"headerlink\" title=\"1.8 批处理\"></a>1.8 批处理</h3><p>Kafka将消息、存储和流处理结合起来，通过组合存储和低延迟订阅，流式应用程序可以以同样的方式处理过去和未来的数据。</p>\n<p>同样，作为流数据管道，能够订阅实时事件使得Kafka具有非常低的延迟；同时Kafka还具有可靠存储数据的特性，可用来存储重要的支付数据，或者与离线系统进行交互，系统可间歇性加载数据，也可在停机维护后再次加载数据。流处理功能使得数据可以在到达时转换数据。</p>\n<h2 id=\"2-0-基本教程\"><a href=\"#2-0-基本教程\" class=\"headerlink\" title=\"2.0 基本教程\"></a>2.0 基本教程</h2><p>如果是windows平台，使用bin\\windows\\而不是bin/，并将脚本扩展名改为.bat</p>\n<h3 id=\"Step-1-下载\"><a href=\"#Step-1-下载\" class=\"headerlink\" title=\"Step 1: 下载\"></a>Step 1: 下载</h3><p><a href=\"https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz\">下载</a>相关版本并解压缩。</p>\n<p><code>&gt; cd kafka</code></p>\n<h3 id=\"Step-2-启动服务器\"><a href=\"#Step-2-启动服务器\" class=\"headerlink\" title=\"Step 2: 启动服务器\"></a>Step 2: 启动服务器</h3><p>Kafka使用<a href=\"https://zookeeper.apache.org/\">ZooKeeper</a>,如果你还没有ZooKeeper服务器。</p>\n<p><code>&gt; bin/zookeeper-server-start.sh config/zookeeper.properties</code></p>\n<p><code>[2021-07-2 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></p>\n<p>开始启动Kafka服务器：</p>\n<p><code>&gt; bin/kafka-server-start.sh config/server.properties</code></p>\n<h3 id=\"Step-3-创建一个topic\"><a href=\"#Step-3-创建一个topic\" class=\"headerlink\" title=\"Step 3: 创建一个topic\"></a>Step 3: 创建一个topic</h3><p>创建一个名为”test”的topic，有一个分区和一个副本：</p>\n<p><code>&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></p>\n<p>现在运行list命令来查看这个topic:</p>\n<p><code>&gt; bin/kafka-topics.sh --list --zookeeper localhost:2181</code></p>\n<p><code>test</code></p>\n<h3 id=\"Step-4-发送消息\"><a href=\"#Step-4-发送消息\" class=\"headerlink\" title=\"Step 4: 发送消息\"></a>Step 4: 发送消息</h3><p>Kafka自带一个命令行客户端，它从文件或标准输入中获取输入，将其作为message发送到Kafka集群。默认情况下，每行将作为单独的message发送。</p>\n<p>运行producer,然后在控制台输入一些消息已发送到服务器。</p>\n<p><code>&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></p>\n<p><code>This is a message</code></p>\n<h3 id=\"Step-5-启动一个consumer\"><a href=\"#Step-5-启动一个consumer\" class=\"headerlink\" title=\"Step 5: 启动一个consumer\"></a>Step 5: 启动一个consumer</h3><p>Kafka有一个命令行consumer，将消息转储到标准输出。</p>\n<p> <code>&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</code></p>\n<p><code>This is a message</code></p>\n<h3 id=\"Step-6-设置多个代理集群\"><a href=\"#Step-6-设置多个代理集群\" class=\"headerlink\" title=\"Step 6: 设置多个代理集群\"></a>Step 6: 设置多个代理集群</h3><p>首先，为每个代理创建一个配置文件（在windows上使用copy命令来代替）：</p>\n<p><code>&gt; cp config/server.properties config/server-1.properties</code></p>\n<p><code>&gt; cp config/server.properties config/server-2.properties</code></p>\n<h3 id=\"Step-7-使用Kafka-Connect来导入-导出数据\"><a href=\"#Step-7-使用Kafka-Connect来导入-导出数据\" class=\"headerlink\" title=\"Step 7: 使用Kafka Connect来导入/导出数据\"></a>Step 7: 使用Kafka Connect来导入/导出数据</h3><p>Kafka Connect是Kafka的一个工具，它可以将数据导入和导出到Kafka。它是一种可扩展工具，通过运行connectors（连接器）， 使用自定义逻辑来实现与外部系统的交互。 在本文中，我们将看到如何使用简单的connectors来运行Kafka Connect，这些connectors 将文件中的数据导入到Kafka topic中，并从中导出数据到一个文件。</p>\n<p>首先，创建一个测试文件：</p>\n<p><code>&gt; echo -e &quot;foo\\nbar&quot; &gt; test.txt</code></p>\n<p>在Windows系统使用：</p>\n<p><code>&gt; echo foo&gt; test.txt</code></p>\n<p><code>&gt; echo bar&gt;&gt; test.txt</code></p>\n<p>接下来，我们将启动两个standalone（独立）运行的连接器，这意味着它们各自运行在一个单独的本地专用 进程上。 我们提供三个配置文件。首先是Kafka Connect的配置文件，包含常用的配置，如Kafka brokers连接方式和数据的序列化格式。 其余的配置文件均指定一个要创建的连接器。这些文件包括连接器的唯一名称，类的实例，以及其他连接器所需的配置。</p>\n<p><code>&gt; bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties</code></p>\n<p>这些包含在Kafka中的示例配置文件使用您之前启动的默认本地群集配置，并创建两个连接器： 第一个是源连接器，用于从输入文件读取行，并将其输入到 Kafka topic。 第二个是接收器连接器，它从Kafka topic中读取消息，并在输出文件中生成一行。</p>\n<p>在启动过程中，你会看到一些日志消息，包括一些连接器正在实例化的指示。 一旦Kafka Connect进程启动，源连接器就开始从 test.txt 读取行并且 将它们生产到主题 connect-test 中，同时接收器连接器也开始从主题 connect-test 中读取消息， 并将它们写入文件 test.sink.txt 中。我们可以通过检查输出文件的内容来验证数据是否已通过整个pipeline进行交付：</p>\n<p><code>&gt; more test.sink.txt</code></p>\n<p><code>foo</code></p>\n<p><code>bar</code></p>\n<p>数据存储在Kafka topic connect-test 中，因此我们也可以运行一个console consumer（控制台消费者）来查看 topic 中的数据（或使用custom consumer（自定义消费者）代码进行处理）：</p>\n<p><code>&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning</code></p>\n<p><code>&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;foo&quot;&#125;</code></p>\n<p><code>&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;bar&quot;&#125;</code></p>\n<p><code>...</code></p>\n<p>连接器一直在处理数据，所以我们可以将数据添加到文件中，并看到它在pipeline 中移动：</p>\n<p><code>&gt; echo Another line&gt;&gt; test.txt</code></p>\n<h3 id=\"Step-8-使用Kafka-Streams来处理数据\"><a href=\"#Step-8-使用Kafka-Streams来处理数据\" class=\"headerlink\" title=\"Step 8: 使用Kafka Streams来处理数据\"></a>Step 8: 使用Kafka Streams来处理数据</h3><p>Kafka Streams是用于构建实时关键应用程序和微服务的客户端库，输入与输出数据存储在Kafka集群中。 Kafka Streams把客户端能够轻便地编写部署标准Java和Scala应用程序的优势与Kafka服务器端集群技术相结合，使这些应用程序具有高度伸缩性、弹性、容错性、分布式等特性。</p>\n<h2 id=\"3-0-使用案例\"><a href=\"#3-0-使用案例\" class=\"headerlink\" title=\"3.0 使用案例\"></a>3.0 使用案例</h2><h3 id=\"3-1-消息\"><a href=\"#3-1-消息\" class=\"headerlink\" title=\"3.1 消息\"></a>3.1 消息</h3><p>Kafka很好的替代了传统的message broker（消息代理）。Message brokers可用于各种场合（如将数据生成器与数据处理解耦，缓冲未处理的消息等）。与大多数消息系统相比，Kafka拥有更好的吞吐量、内置分区、具有复制和容错功能，这使他成为一个非常理想的大型消息处理应用。</p>\n<h3 id=\"3-2-跟踪网站活动\"><a href=\"#3-2-跟踪网站活动\" class=\"headerlink\" title=\"3.2 跟踪网站活动\"></a>3.2 跟踪网站活动</h3><p>Kafka的初始用例是将用户活动跟踪管道重建为一组实时发布-订阅源。这意味着网站活动（浏览网页、搜索或其他的用户操作）将被发布到中心topic，其中每个活动类型有一个topic。这些订阅源提供一系列用例，包括实时处理、实时监视、对加载到Hadoop或离线数据仓库系统的数据进行离线处理和报告等。</p>\n<h3 id=\"3-3-度量\"><a href=\"#3-3-度量\" class=\"headerlink\" title=\"3.3 度量\"></a>3.3 度量</h3><p>Kafka通常用于监控数据。这涉及到从分布式应用程序中汇总数据，然后生成可操作的集中数据源。</p>\n<h3 id=\"3-4-日志聚合\"><a href=\"#3-4-日志聚合\" class=\"headerlink\" title=\"3.4 日志聚合\"></a>3.4 日志聚合</h3><p>日志聚合系统通常从服务器收集物理日志文件，并将其置于一个中心系统（可能是文件服务器或HDFS）进行处理。Kafka从这些日志文件中提取信息，并将其抽象为一个更加清晰的消息流。这样可以实现更低的延迟处理且易于支持多个数据源及分布式数据的消耗。</p>\n<h3 id=\"3-5-流处理\"><a href=\"#3-5-流处理\" class=\"headerlink\" title=\"3.5 流处理\"></a>3.5 流处理</h3><p>Kafka用户通过管道来处理数据，有多个阶段： 从Kafka topic中消费原始输入数据，然后聚合，修饰或通过其他方式转化为新的topic， 以供进一步消费或处理。Kafka Streams是一个轻量但功能强大的流处理库。</p>\n<h3 id=\"3-6-采集日志\"><a href=\"#3-6-采集日志\" class=\"headerlink\" title=\"3.6 采集日志\"></a>3.6 采集日志</h3><p><a href=\"https://martinfowler.com/eaaDev/EventSourcing.html\">Event sourcing</a>是一种应用程序设计风格，按时间来记录状态的更改。 Kafka 可以存储非常多的日志数据，为基于 event sourcing 的应用程序提供强有力的支持。</p>\n<h3 id=\"3-7-提交日志\"><a href=\"#3-7-提交日志\" class=\"headerlink\" title=\"3.7 提交日志\"></a>3.7 提交日志</h3><p>Kafka 可以从外部为分布式系统提供日志提交功能。 日志有助于记录节点和行为间的数据，采用重新同步机制可以从失败节点恢复数据。 Kafka的日志压缩 功能支持这一用法。</p>\n<p><a href=\"https://kafka.apache.org/documentation/#gettingStarted\">有关Kafka提供的保证、API和功能的更多信息，请查看相关文档。</a></p>\n","site":{"data":{"galleries":[{"name":"记事","cover":"/images/theme/post-image.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]},{"name":"厦门旅拍","cover":"/images/xiamen/welcome_dark_1.jpg","description":"翻开随身携带的记事本，写着许多事都是关于你。","photos":["/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg","/images/xiamen/welcome_dark_1.jpg"]}],"local_images":["/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg","/images/theme/post-image.jpg"]}},"excerpt":"","more":"<h1 id=\"Apache-Kafka-是一个分布式流处理平台。\"><a href=\"#Apache-Kafka-是一个分布式流处理平台。\" class=\"headerlink\" title=\"Apache Kafka 是一个分布式流处理平台。\"></a><strong>Apache Kafka 是一个分布式流处理平台。</strong></h1><h2 id=\"1-0-介绍\"><a href=\"#1-0-介绍\" class=\"headerlink\" title=\"1.0 介绍\"></a>1.0 介绍</h2><p>kafka 作为一个集群，运行在一台或者多台服务器上，它是通过topic对存储的流数据进行分类。每条记录中包含一个key,一个value和一个timestamp(时间戳)。</p>\n<p>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p>\n<p>kafka有四个核心的API：</p>\n<ul>\n<li>Producer API允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。</li>\n<li>Consumer API允许一个应用程序订阅一个或者多个topic,并且对发布给他们的流式数据进行处理。</li>\n<li>Streams API允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后产生一个输出流到一个或者多个topic中去，在输入输出流中进行有效的转换。</li>\n<li>Connector API允许构建并运行可重用的生产者或者消费者，将Kafka Topic连接到已经存在的应用程序或者数据系统。<br><img src=\"/images/kafka/kafka-apis.png\"></li>\n</ul>\n<h3 id=\"1-1-相关术语\"><a href=\"#1-1-相关术语\" class=\"headerlink\" title=\"1.1 相关术语\"></a>1.1 相关术语</h3><h4 id=\"1-1-1-broker\"><a href=\"#1-1-1-broker\" class=\"headerlink\" title=\"1.1.1 broker\"></a>1.1.1 broker</h4><p>Kafka 集群包含一个或多个服务器，服务器节点称为broker。</p>\n<p>broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。</p>\n<p>如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</p>\n<p>如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</p>\n<h4 id=\"1-1-2-Topic\"><a href=\"#1-1-2-Topic\" class=\"headerlink\" title=\"1.1.2 Topic\"></a>1.1.2 Topic</h4><p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>\n<p>类似于数据库的表名</p>\n<h4 id=\"1-1-3-Partition\"><a href=\"#1-1-3-Partition\" class=\"headerlink\" title=\"1.1.3 Partition\"></a>1.1.3 Partition</h4><p>topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</p>\n<h4 id=\"1-1-4-Producer\"><a href=\"#1-1-4-Producer\" class=\"headerlink\" title=\"1.1.4 Producer\"></a>1.1.4 Producer</h4><p>生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。</p>\n<h4 id=\"1-1-5-Consumer\"><a href=\"#1-1-5-Consumer\" class=\"headerlink\" title=\"1.1.5 Consumer\"></a>1.1.5 Consumer</h4><p>消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。</p>\n<h4 id=\"1-1-6-Consumer-Group\"><a href=\"#1-1-6-Consumer-Group\" class=\"headerlink\" title=\"1.1.6 Consumer Group\"></a>1.1.6 Consumer Group</h4><p>每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</p>\n<h4 id=\"1-1-7-Leader\"><a href=\"#1-1-7-Leader\" class=\"headerlink\" title=\"1.1.7 Leader\"></a>1.1.7 Leader</h4><p>每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。</p>\n<h4 id=\"1-1-8-Follower\"><a href=\"#1-1-8-Follower\" class=\"headerlink\" title=\"1.1.8 Follower\"></a>1.1.8 Follower</h4><p>Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。</p>\n<h3 id=\"1-2-Topics和日志\"><a href=\"#1-2-Topics和日志\" class=\"headerlink\" title=\"1.2 Topics和日志\"></a>1.2 Topics和日志</h3><p>Topic 是数据主题，是数据记录发布的地方，可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费之来订阅它的数据。</p>\n<p>每一个topic，Kafka集群会维持一个分区日志。</p>\n<p><img src=\"/images/kafka/log_anatomy.png\"></p>\n<p>每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id来表示顺序，我们称为offset,offset用来唯一的标识分区中的每一条数据。</p>\n<p>kafka的性能和数据大小无关，所以长时间存储数据没什么问题。</p>\n<p>日志中的partition分区有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可以有多个分区，因此可以处理无限量的数据。第二，可以作为并行的单元集。</p>\n<h3 id=\"1-3-分布式\"><a href=\"#1-3-分布式\" class=\"headerlink\" title=\"1.3 分布式\"></a>1.3 分布式</h3><p>日志的分区partition分布在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。</p>\n<p>每个分区都有一台server作为“leader”， 0台或者多台server作为follers.leader server处理一切对partition分区的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers中的一台服务器会自动成为新的leader。每台server都会成为某些分区的leader和某些分区的follower，因此集群的负载是平衡的。</p>\n<h3 id=\"1-4-生产者\"><a href=\"#1-4-生产者\" class=\"headerlink\" title=\"1.4 生产者\"></a>1.4 生产者</h3><p>生产者可以将数据发布到所选择的topic(主题)中。生产者负责记录分配到topic中的某个partition分区中。可以使用循环的方式来简单地实现负载均衡。</p>\n<h3 id=\"1-5-消费者\"><a href=\"#1-5-消费者\" class=\"headerlink\" title=\"1.5 消费者\"></a>1.5 消费者</h3><p>消费者使用一个消费组名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的消费者实例。消费者实例可以分布在多个进程中或者多个机器上。</p>\n<p>如果所有的消费者实例在同一消费组中，消费记录会负载均衡到每一个消费者实例。</p>\n<p>如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程。<br><img src=\"/images/kafka/consumer_groups.png\"></p>\n<p>如图，这个Kafka集群有两台server，四个分区和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。</p>\n<p>通常情况下，每个topic都会有一些消费组，一个消费组对应一个“逻辑订阅者”。 一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个进程。</p>\n<p>在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费者组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些partition分区；如果一个实例消失，拥有的分区将被分发至剩余的实例。</p>\n<p>Kafka只保证分区内记录是有序的，不保证主题中不同分区的顺序。</p>\n<h3 id=\"1-6-Kafka作为存储系统\"><a href=\"#1-6-Kafka作为存储系统\" class=\"headerlink\" title=\"1.6 Kafka作为存储系统\"></a>1.6 Kafka作为存储系统</h3><p>数据写入Kafka后被写入到磁盘，并且备份以便容错，直到完全备份，Kafka才让生产者认为完成写入，即使写入失败kafka也会确保继续写入Kafka使用磁盘结构，具有很好的扩展性。</p>\n<p>Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。</p>\n<h3 id=\"1-7-Kafka用作流处理\"><a href=\"#1-7-Kafka用作流处理\" class=\"headerlink\" title=\"1.7 Kafka用作流处理\"></a>1.7 Kafka用作流处理</h3><p>Kafka流处理不仅用来读写和存储流式数据，最终目的是为了能够进行实时的流处理。在Kafka中，流处理不断地从输入的topic获取流数据，处理数据后，在不断生产数据到输出的topic中去。</p>\n<p>简单数据处理可以使用生产者和消费者的API。对于复杂的数据变换，Kafka提供了Streams　API。Stream　API允许应用做一些复杂的处理，比如将流数据聚合或者join。</p>\n<p>这一功能有助于解决以下这种应用程序面临的问题：处理无序数据，当消费端代码变更后重新处理输入，执行有状态计算等。</p>\n<p>Streams API建立在Kafka的核心之上：它使用Producer和Consumer API作为输入，使用Kafka进行有状态的存储，并在流处理实例之间使用相同的消费组机制来实现容错。</p>\n<h3 id=\"1-8-批处理\"><a href=\"#1-8-批处理\" class=\"headerlink\" title=\"1.8 批处理\"></a>1.8 批处理</h3><p>Kafka将消息、存储和流处理结合起来，通过组合存储和低延迟订阅，流式应用程序可以以同样的方式处理过去和未来的数据。</p>\n<p>同样，作为流数据管道，能够订阅实时事件使得Kafka具有非常低的延迟；同时Kafka还具有可靠存储数据的特性，可用来存储重要的支付数据，或者与离线系统进行交互，系统可间歇性加载数据，也可在停机维护后再次加载数据。流处理功能使得数据可以在到达时转换数据。</p>\n<h2 id=\"2-0-基本教程\"><a href=\"#2-0-基本教程\" class=\"headerlink\" title=\"2.0 基本教程\"></a>2.0 基本教程</h2><p>如果是windows平台，使用bin\\windows\\而不是bin/，并将脚本扩展名改为.bat</p>\n<h3 id=\"Step-1-下载\"><a href=\"#Step-1-下载\" class=\"headerlink\" title=\"Step 1: 下载\"></a>Step 1: 下载</h3><p><a href=\"https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz\">下载</a>相关版本并解压缩。</p>\n<p><code>&gt; cd kafka</code></p>\n<h3 id=\"Step-2-启动服务器\"><a href=\"#Step-2-启动服务器\" class=\"headerlink\" title=\"Step 2: 启动服务器\"></a>Step 2: 启动服务器</h3><p>Kafka使用<a href=\"https://zookeeper.apache.org/\">ZooKeeper</a>,如果你还没有ZooKeeper服务器。</p>\n<p><code>&gt; bin/zookeeper-server-start.sh config/zookeeper.properties</code></p>\n<p><code>[2021-07-2 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)</code></p>\n<p>开始启动Kafka服务器：</p>\n<p><code>&gt; bin/kafka-server-start.sh config/server.properties</code></p>\n<h3 id=\"Step-3-创建一个topic\"><a href=\"#Step-3-创建一个topic\" class=\"headerlink\" title=\"Step 3: 创建一个topic\"></a>Step 3: 创建一个topic</h3><p>创建一个名为”test”的topic，有一个分区和一个副本：</p>\n<p><code>&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></p>\n<p>现在运行list命令来查看这个topic:</p>\n<p><code>&gt; bin/kafka-topics.sh --list --zookeeper localhost:2181</code></p>\n<p><code>test</code></p>\n<h3 id=\"Step-4-发送消息\"><a href=\"#Step-4-发送消息\" class=\"headerlink\" title=\"Step 4: 发送消息\"></a>Step 4: 发送消息</h3><p>Kafka自带一个命令行客户端，它从文件或标准输入中获取输入，将其作为message发送到Kafka集群。默认情况下，每行将作为单独的message发送。</p>\n<p>运行producer,然后在控制台输入一些消息已发送到服务器。</p>\n<p><code>&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></p>\n<p><code>This is a message</code></p>\n<h3 id=\"Step-5-启动一个consumer\"><a href=\"#Step-5-启动一个consumer\" class=\"headerlink\" title=\"Step 5: 启动一个consumer\"></a>Step 5: 启动一个consumer</h3><p>Kafka有一个命令行consumer，将消息转储到标准输出。</p>\n<p> <code>&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</code></p>\n<p><code>This is a message</code></p>\n<h3 id=\"Step-6-设置多个代理集群\"><a href=\"#Step-6-设置多个代理集群\" class=\"headerlink\" title=\"Step 6: 设置多个代理集群\"></a>Step 6: 设置多个代理集群</h3><p>首先，为每个代理创建一个配置文件（在windows上使用copy命令来代替）：</p>\n<p><code>&gt; cp config/server.properties config/server-1.properties</code></p>\n<p><code>&gt; cp config/server.properties config/server-2.properties</code></p>\n<h3 id=\"Step-7-使用Kafka-Connect来导入-导出数据\"><a href=\"#Step-7-使用Kafka-Connect来导入-导出数据\" class=\"headerlink\" title=\"Step 7: 使用Kafka Connect来导入/导出数据\"></a>Step 7: 使用Kafka Connect来导入/导出数据</h3><p>Kafka Connect是Kafka的一个工具，它可以将数据导入和导出到Kafka。它是一种可扩展工具，通过运行connectors（连接器）， 使用自定义逻辑来实现与外部系统的交互。 在本文中，我们将看到如何使用简单的connectors来运行Kafka Connect，这些connectors 将文件中的数据导入到Kafka topic中，并从中导出数据到一个文件。</p>\n<p>首先，创建一个测试文件：</p>\n<p><code>&gt; echo -e &quot;foo\\nbar&quot; &gt; test.txt</code></p>\n<p>在Windows系统使用：</p>\n<p><code>&gt; echo foo&gt; test.txt</code></p>\n<p><code>&gt; echo bar&gt;&gt; test.txt</code></p>\n<p>接下来，我们将启动两个standalone（独立）运行的连接器，这意味着它们各自运行在一个单独的本地专用 进程上。 我们提供三个配置文件。首先是Kafka Connect的配置文件，包含常用的配置，如Kafka brokers连接方式和数据的序列化格式。 其余的配置文件均指定一个要创建的连接器。这些文件包括连接器的唯一名称，类的实例，以及其他连接器所需的配置。</p>\n<p><code>&gt; bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties</code></p>\n<p>这些包含在Kafka中的示例配置文件使用您之前启动的默认本地群集配置，并创建两个连接器： 第一个是源连接器，用于从输入文件读取行，并将其输入到 Kafka topic。 第二个是接收器连接器，它从Kafka topic中读取消息，并在输出文件中生成一行。</p>\n<p>在启动过程中，你会看到一些日志消息，包括一些连接器正在实例化的指示。 一旦Kafka Connect进程启动，源连接器就开始从 test.txt 读取行并且 将它们生产到主题 connect-test 中，同时接收器连接器也开始从主题 connect-test 中读取消息， 并将它们写入文件 test.sink.txt 中。我们可以通过检查输出文件的内容来验证数据是否已通过整个pipeline进行交付：</p>\n<p><code>&gt; more test.sink.txt</code></p>\n<p><code>foo</code></p>\n<p><code>bar</code></p>\n<p>数据存储在Kafka topic connect-test 中，因此我们也可以运行一个console consumer（控制台消费者）来查看 topic 中的数据（或使用custom consumer（自定义消费者）代码进行处理）：</p>\n<p><code>&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning</code></p>\n<p><code>&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;foo&quot;&#125;</code></p>\n<p><code>&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;bar&quot;&#125;</code></p>\n<p><code>...</code></p>\n<p>连接器一直在处理数据，所以我们可以将数据添加到文件中，并看到它在pipeline 中移动：</p>\n<p><code>&gt; echo Another line&gt;&gt; test.txt</code></p>\n<h3 id=\"Step-8-使用Kafka-Streams来处理数据\"><a href=\"#Step-8-使用Kafka-Streams来处理数据\" class=\"headerlink\" title=\"Step 8: 使用Kafka Streams来处理数据\"></a>Step 8: 使用Kafka Streams来处理数据</h3><p>Kafka Streams是用于构建实时关键应用程序和微服务的客户端库，输入与输出数据存储在Kafka集群中。 Kafka Streams把客户端能够轻便地编写部署标准Java和Scala应用程序的优势与Kafka服务器端集群技术相结合，使这些应用程序具有高度伸缩性、弹性、容错性、分布式等特性。</p>\n<h2 id=\"3-0-使用案例\"><a href=\"#3-0-使用案例\" class=\"headerlink\" title=\"3.0 使用案例\"></a>3.0 使用案例</h2><h3 id=\"3-1-消息\"><a href=\"#3-1-消息\" class=\"headerlink\" title=\"3.1 消息\"></a>3.1 消息</h3><p>Kafka很好的替代了传统的message broker（消息代理）。Message brokers可用于各种场合（如将数据生成器与数据处理解耦，缓冲未处理的消息等）。与大多数消息系统相比，Kafka拥有更好的吞吐量、内置分区、具有复制和容错功能，这使他成为一个非常理想的大型消息处理应用。</p>\n<h3 id=\"3-2-跟踪网站活动\"><a href=\"#3-2-跟踪网站活动\" class=\"headerlink\" title=\"3.2 跟踪网站活动\"></a>3.2 跟踪网站活动</h3><p>Kafka的初始用例是将用户活动跟踪管道重建为一组实时发布-订阅源。这意味着网站活动（浏览网页、搜索或其他的用户操作）将被发布到中心topic，其中每个活动类型有一个topic。这些订阅源提供一系列用例，包括实时处理、实时监视、对加载到Hadoop或离线数据仓库系统的数据进行离线处理和报告等。</p>\n<h3 id=\"3-3-度量\"><a href=\"#3-3-度量\" class=\"headerlink\" title=\"3.3 度量\"></a>3.3 度量</h3><p>Kafka通常用于监控数据。这涉及到从分布式应用程序中汇总数据，然后生成可操作的集中数据源。</p>\n<h3 id=\"3-4-日志聚合\"><a href=\"#3-4-日志聚合\" class=\"headerlink\" title=\"3.4 日志聚合\"></a>3.4 日志聚合</h3><p>日志聚合系统通常从服务器收集物理日志文件，并将其置于一个中心系统（可能是文件服务器或HDFS）进行处理。Kafka从这些日志文件中提取信息，并将其抽象为一个更加清晰的消息流。这样可以实现更低的延迟处理且易于支持多个数据源及分布式数据的消耗。</p>\n<h3 id=\"3-5-流处理\"><a href=\"#3-5-流处理\" class=\"headerlink\" title=\"3.5 流处理\"></a>3.5 流处理</h3><p>Kafka用户通过管道来处理数据，有多个阶段： 从Kafka topic中消费原始输入数据，然后聚合，修饰或通过其他方式转化为新的topic， 以供进一步消费或处理。Kafka Streams是一个轻量但功能强大的流处理库。</p>\n<h3 id=\"3-6-采集日志\"><a href=\"#3-6-采集日志\" class=\"headerlink\" title=\"3.6 采集日志\"></a>3.6 采集日志</h3><p><a href=\"https://martinfowler.com/eaaDev/EventSourcing.html\">Event sourcing</a>是一种应用程序设计风格，按时间来记录状态的更改。 Kafka 可以存储非常多的日志数据，为基于 event sourcing 的应用程序提供强有力的支持。</p>\n<h3 id=\"3-7-提交日志\"><a href=\"#3-7-提交日志\" class=\"headerlink\" title=\"3.7 提交日志\"></a>3.7 提交日志</h3><p>Kafka 可以从外部为分布式系统提供日志提交功能。 日志有助于记录节点和行为间的数据，采用重新同步机制可以从失败节点恢复数据。 Kafka的日志压缩 功能支持这一用法。</p>\n<p><a href=\"https://kafka.apache.org/documentation/#gettingStarted\">有关Kafka提供的保证、API和功能的更多信息，请查看相关文档。</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckqu9t2qh000by8va9wfbd0gb","category_id":"ckqu9t2qe0008y8vaes7z0tz9","_id":"ckqu9t2qk000gy8vafcbx23j8"},{"post_id":"ckqu9t2q90006y8vahrtyb0ku","category_id":"ckqu9t2qe0008y8vaes7z0tz9","_id":"ckqu9t2qk000hy8va3loq7lgb"},{"post_id":"ckqu9t2qi000cy8va9oj0b5wl","category_id":"ckqu9t2qj000ey8vaao7v0c1h","_id":"ckqu9t2qk000iy8vaf49jb8l4"},{"post_id":"ckqu9t2ql000jy8va9ihacu3u","category_id":"ckqu9t2qe0008y8vaes7z0tz9","_id":"ckqu9t2qm000ly8va3ei30lhs"}],"PostTag":[{"post_id":"ckqu9t2qh000by8va9wfbd0gb","tag_id":"ckqu9t2qf0009y8vabhzg3jax","_id":"ckqu9t2qj000dy8vagj116jqt"},{"post_id":"ckqu9t2q90006y8vahrtyb0ku","tag_id":"ckqu9t2qf0009y8vabhzg3jax","_id":"ckqu9t2qk000fy8va6cqy89pn"},{"post_id":"ckqu9t2ql000jy8va9ihacu3u","tag_id":"ckqu9t2qf0009y8vabhzg3jax","_id":"ckqu9t2qm000ky8vabzjz4uwc"}],"Tag":[{"name":"Kafka","_id":"ckqu9t2qf0009y8vabhzg3jax"}]}}